{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "# our models of choice\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.59\n",
      "transformers version : 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers model Zoo\n",
    "Create a dictionary of parameters required for creating different model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make model selection here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 16\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-uncased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "#model_type = 'xlm'\n",
    "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "\n",
    "#model_type = 'xlnet'\n",
    "#pretrained_model_name = 'xlnet-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the same randomization seed so as to compare different models more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "The important thing here is that `FastAI` uses **processors** to perform repeatetive tasks when creating `DataBunch`. A set of default **processors** are performed for fastai.textlearners. For example:\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAI use various processors to perform repeatative tasks in data pipeline\n",
    "\n",
    "def _get_processor(tokenizer:Tokenizer=None, vocab:Vocab=None, chunksize:int=10000, max_vocab:int=60000,\n",
    "                   min_freq:int=2, mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False):\n",
    "    return [TokenizeProcessor(tokenizer=tokenizer, chunksize=chunksize, \n",
    "                              mark_fields=mark_fields, include_bos=include_bos, include_eos=include_eos),\n",
    "            NumericalizeProcessor(vocab=vocab, max_vocab=max_vocab, min_freq=min_freq)]\n",
    "\n",
    "class NumericalizeProcessor(PreProcessor):\n",
    "    \"`PreProcessor` that numericalizes the tokens in `ds`.\"\n",
    "    def __init__(self, ds:ItemList=None, vocab:Vocab=None, max_vocab:int=60000, min_freq:int=3):\n",
    "        vocab = ifnone(vocab, ds.vocab if ds is not None else None)\n",
    "        self.vocab,self.max_vocab,self.min_freq = vocab,max_vocab,min_freq\n",
    "\n",
    "    def process_one(self,item): return np.array(self.vocab.numericalize(item), dtype=np.int64)\n",
    "    def process(self, ds):\n",
    "        if self.vocab is None: self.vocab = Vocab.create(ds.items, self.max_vocab, self.min_freq)\n",
    "        ds.vocab = self.vocab\n",
    "        super().process(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to overwrite the \"tokenizer\" and \"numericalizer\" in order to tailor the databunch creating process to the `Transformers`\n",
    "Later when creating `DataBunch`, we are going to pass in our customized processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "Step 1: create a new tokenizer that inherit from `fastai`'s `BaseTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "        return [CLS] + tokens + [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Get the 'pre-trained tokenizer' from `transformer` library.(this is used for initialization of the class we created above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create the actual **tokenizer** for our transformer of choice and put a `FastAI` wrapper on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.transform.Tokenizer"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roberta'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, be carefull about 3 things :\n",
    "\n",
    "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
    "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
    "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with add_prefix_space set to True.\n",
    "\n",
    "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the [HuggingFace documentation](https://huggingface.co/transformers/) in each model section.<br>\n",
    "`bert:       [CLS] + tokens + [SEP] + padding`<br>\n",
    "`roberta:    [CLS] + prefix_space + tokens + [SEP] + padding`<br>\n",
    "`distilbert: [CLS] + tokens + [SEP] + padding`<br>\n",
    "`xlm:        [CLS] + tokens + [SEP] + padding`<br>\n",
    "`xlnet:      padding + [CLS] + tokens + [SEP]`\n",
    "\n",
    "It is worth noting that we don't add padding in this part of the implementation.  As we will see later, fastai manage it automatically during the creation of the `DataBunch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalizer\n",
    "In `fastai` library, `NumericalizeProcessor` object takes as `bocab` argument a `Vocab` object. Here we will create a new class `TransformerVocab` that inherits from `Vocab` and overwrite `numericalize` and `textify` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize numericalize processor\n",
    "Notice taht we need to pass the `include_bs=False` and `include_eos=False` options. This is because `fastiai` adds its own special tokens by default which interferes with the `[CLS]` and `[SEP]` tokens that are required for RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.NumericalizeProcessor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumericalizeProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use RoBERTa tokenizer to initialize the `TransformersVocab\n",
    "transformer_vocab = TransformersVocab(tokenizer=transformer_tokenizer)\n",
    "\n",
    "# create a customized numericalizor using vocab just created\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put together our customized processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.TokenizeProcessor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenizeProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function over the tokenizer we created above\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(TextList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally put the two processors in a list for later use\n",
    "transformer_processor = [OpenFileProcessor(),tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataBunch\n",
    "For the DataBunch creation, you have to pay attention to set the processor argument to our new custom processor `transformer_processor` and manage correctly the padding.\n",
    "\n",
    "As mentioned in the [HuggingFace documentation](https://huggingface.co/transformers/), BERT, RoBERTa, XLM and DistilBERT are models with absolute position embeddings, so it's usually advised to pad the inputs on the right rather than the left. Regarding XLNET, it is a model with relative position embeddings, therefore, you can either pad the inputs on the right or on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are using Google XLNet\n",
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'Ġcat', 'Ġdidnt', 'Ġjump', 'Ġonto', 'Ġthe', 'Ġtable', ',', 'Ġbecause', 'Ġits', 'Ġtired']\n",
      "[627, 4758, 46405, 3704, 2500, 5, 2103, 6, 142, 63, 7428]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'Ġcat',\n",
       " 'Ġdidnt',\n",
       " 'Ġjump',\n",
       " 'Ġonto',\n",
       " 'Ġthe',\n",
       " 'Ġtable',\n",
       " ',',\n",
       " 'Ġbecause',\n",
       " 'Ġits',\n",
       " 'Ġtired']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('the cat didnt jump onto the table, because its tired')\n",
    "print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the full IMDB dataset and inspect the files under that path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/projectx/.fastai/data/imdb')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/lm_databunch_RoBERTa'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/test'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/data_bunch_classification'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/imdb_textlist_classifier'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/lm_databunch'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/pos'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/neg')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/test/pos'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/test/labeledBow.feat'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/test/neg')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'test').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for LM training\n",
    "The reviews are in a training and test folder. In addition, we have a 'unsup' folder that contains many reviews are \n",
    "are **not labelled**.<br>\n",
    "In the second training phase of ULMFiT, as mentioned in the [README](https://github.com/Sylar257/Sentiment-Analysis/blob/master/README.md)\n",
    ", we will be fine-tuning the language model to the domain-specific corpus.<br>\n",
    "Thus, training could take advantage of using 'train', 'test', and 'unsup' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataBunch for language model\n",
    "What does that mean?<br>\n",
    "Basically we are creating a databunch for our learner later in a way that we ignore the true label('negataive' or  'positive'). Hence, the task we constructed is as simple as to just predict the **next word** without worrying about what the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(TextList.label_for_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we can play around with the batch_size as long as the GPU can take it\n",
    "bs = 32\n",
    "data_lm = (TextList.from_folder(path, processor=transformer_processor)                         # specify the path\n",
    "           .filter_by_folder(include=['train','test','unsup'])# exclude other folders\n",
    "           .split_by_rand_pct(0.1, seed=seed)                 # randomly split and keep 10% for validation set\n",
    "           .label_for_lm()                                    # label as to \"predict the next word token\"\n",
    "           .databunch(bs=bs)) # convert to databunch for the learner later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.train_ds), len(data_lm.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ġhave Ġa Ġweak spot Ġfor Ġromantic Ġcomed ies Ġ( I Ġdon 't Ġknow Ġwhy ). ĠThe Ġtrailers ĠI Ġsaw Ġwere Ġnot Ġappealing , Ġthe Ġcast Ġdid Ġnot Ġlook Ġthat Ġinteresting Ġand ĠI Ġhad Ġno Ġidea Ġwhat Ġthe Ġplot Ġwould Ġbe Ġabout . ĠIn Ġthe Ġend ĠI Ġfound Ġit Ġto Ġbe Ġan Ġinteresting Ġmeditation Ġon Ġrelationships Ġand Ġfamily . ĠI Ġthoroughly Ġenjoyed Ġmyself Ġand Ġmust Ġadmit Ġthat ĠI Ġthought Ġthat Ġthis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ġup Ġto Ġbecome Ġthe Ġtrue Ġleader Ġof Ġthis Ġgang Ġof Ġmessed - up Ġret ards Ġ( I Ġmean Ġthis Ġin Ġthe Ġbest Ġpossible Ġway ). ĠI Ġfirst Ġthought , Ġmaybe ĠBam Ġor ĠSteve - O Ġwere Ġthe Ġmain Ġgo - to Ġguys .... n ope , Ġthe Ġmain Ġman Ġis Ġnow ĠJohnny . ĠDon 't Ġget Ġme Ġwrong , Ġeverybody , Ġand ĠI Ġmean Ġeverybody Ġis Ġgreat Ġin Ġthis Ġflick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ĠMY Ġwords ?\" ĠThe Ġanswer Ġof Ġcourse , Ġis Ġsure , Ġwe Ġall Ġdo . ĠIt 's Ġunfortunate Ġthat Ġmost Ġof Ġthe Ġg aff es Ġin Ġthis Ġrespect Ġcome Ġearly Ġin Ġthe Ġpicture , Ġbecause , Ġby Ġabout Ġtwenty Ġminutes , Ġyou 've Ġsunk Ġso Ġdeep Ġin Ġyou Ġwouldn 't Ġknow Ġit Ġif Ġa Ġbomb Ġwent Ġoff Ġbehind Ġyou .&lt; br Ġ/ &gt;&lt; br Ġ/&gt; The Ġnext Ġthing Ġyou Ġnotice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ġthat Ġon Ġoccasions ĠI Ġwanted Ġto Ġgrab Ġgun Ġfrom ĠNorman Ġand Ġshoot Ġthat Ġsnake Ġgirl . ĠHe he . ĠI Ġlike Ġthe Ġmovies Ġwhen Ġinnocent Ġlooking Ġgirls Ġplay Ġtricks Ġwith Ġmen Ġreally Ġcunning ly . ĠThe Ġending Ġwas Ġwhat ĠI Ġwanted Ġ: )) Ġ&lt; br Ġ/ &gt;&lt; br Ġ/&gt; This Ġmovie Ġis Ġfilled Ġwith Ġtwists Ġof Ġmoments . ĠYou Ġexpect Ġthis Ġbut Ġsomething Ġelse Ġhappens . Ġ&lt; br Ġ/ &gt;&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ĠAlien Ġmovies Ġto Ġmake Ġthis Ġclassic Ġpiece Ġof Ġgarbage .&lt; br Ġ/ &gt;&lt; br Ġ/&gt; Cast Ġmembers Ġsuch Ġas ĠR . ĠLee ĠEr me y Ġand ĠRay ĠWise Ġwere Ġthe Ġonly Ġtwo Ġactors Ġwith Ġany Ġtalent Ġand Ġthe Ġlead Ġ\" Jack ĠScalia \" Ġwas Ġreally Ġabsolutely Ġhorrible . ĠI Ġthink Ġthey Ġcast Ġhim Ġfor Ġhis Ġmassive Ġcle ft Ġchin . ĠI Ġwas Ġalso Ġannoyed Ġwith Ġthe Ġstereotyp ing Ġof Ġthe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a peek at a small sample of data\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save our databunch so that we don't have to re-run this the next time\n",
    "data_lm.save('lm_databunch_RoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the databunch we created ealier\n",
    "# bs = 48\n",
    "# data_lm = load_data(path, 'lm_databunch_RoBERTa', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : <s>\n",
      "[SEP] token : </s>\n",
      "[PAD] token : <pad>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ġfilm Ġwas Ġone Ġof Ġthe Ġmost Ġoverlooked Ġgems Ġof Ġlast Ġyear . ĠI Ġam Ġdisappointed Ġthat Ġso Ġfew Ġpeople Ġseemed Ġto Ġhave Ġenjoyed Ġthe Ġvery Ġ\" human - ness \" Ġthat Ġthis Ġmovie Ġpresented Ġthe Ġviewer Ġwith .&lt; br Ġ/ &gt;&lt; br Ġ/&gt; I Ġhave Ġread Ġmany Ġbad Ġreviews Ġof Ġthis Ġfilm , Ġand Ġmust Ġadmit Ġa Ġcertain Ġlevel Ġof Ġshock Ġat Ġthe Ġcynicism Ġthat Ġis Ġprevalent Ġin Ġthem .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>! ĠRight Ġfrom Ġthe Ġget - go Ġyou 're Ġlaughing , Ġand Ġbelieve Ġyou Ġme , Ġdon 't Ġplan Ġon Ġresting Ġthat Ġsmile Ġof Ġyours . ĠI Ġpersonally Ġthink Ġthe Ġmovie Ġdefinitely Ġhas Ġbetter Ġmoments Ġthan Ġthe Ġfirst . ĠYou Ġknow Ġwhen Ġyou Ġgo Ġinto Ġa Ġtheater , Ġand Ġyou Ġkind Ġof Ġdon 't Ġwant Ġto Ġhave Ġhigh Ġexpectations Ġfor Ġit ..... well , Ġthis Ġmovie Ġblows Ġall Ġexpectations Ġaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>... or Ġmaybe Ġyou Ġnotice Ġit Ġhours Ġor Ġdays Ġafter Ġthe Ġfilm Ġends , Ġis Ġthat Ġyou Ġnever Ġsaw Ġany Ġsubstantial Ġplot , Ġyet Ġthe Ġthemes Ġand Ġthe Ġpoetry Ġof Ġthe Ġdialog Ġand Ġcharacters Ġnever Ġleave Ġyou . ĠIn Ġfact , Ġthe Ġtreatment Ġof Ġthe Ġrole Ġrace Ġplays Ġin Ġthe Ġeveryday Ġlives Ġof Ġthese Ġcharacters Ġis Ġalways Ġthere , Ġbut Ġit 's Ġso Ġep hemer al Ġthat Ġeven Ġthey Ġaren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>br Ġ/&gt; In Ġthe Ġbeginning , Ġthose Ġmassive Ġimages Ġcut Ġscenes Ġwere Ġreally Ġpainful Ġto Ġeyes .&lt; br Ġ/ &gt;&lt; br Ġ/&gt; Although Ġit Ġwas Ġnot Ġshown Ġwhen ĠNorman ĠReed us Ġchanged Ġcurrency Ġnotes ? ĠOr Ġis Ġit Ġme Ġstanding Ġby Ġfridge . Ġ:) &lt;/s&gt; &lt;s&gt; ĠJoseph ĠConrad 's Ġtimeless Ġnovel , ĠHeart Ġof ĠDarkness , Ġwas Ġdepicted Ġin Ġthe Ġ1994 Ġmovie . ĠI Ġhave Ġread ĠConrad 's Ġnovel ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Ġonly Ġblack Ġmale Ġon Ġthe Ġset ĠJohn ĠT oles - Bey Ġwho Ġmust Ġlook Ġat Ġthis Ġmovie Ġand Ġjust Ġwonder . ĠLook Ġhim Ġup Ġsometime Ġas Ġhe Ġhas Ġdone Ġa Ġlot Ġof Ġinteresting Ġmovies .&lt; br Ġ/ &gt;&lt; br Ġ/&gt; But Ġon Ġthis Ġmovie : ĠThe Ġscript Ġas ĠI Ġsaid Ġearlier Ġwas Ġa Ġrip - off Ġof ĠAliens Ġtweaked Ġand Ġturned Ġinto Ġa Ġsubmarine Ġ\" th r iller \". ĠIt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a sanity check for <s>; </s>; <pad>\n",
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We would be feeding for each batch size of `32` and bptt of `70` (This is by defaul of FastAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 0\n",
      "[SEP] id : 2\n",
      "[PAD] id : 1\n",
      "Batch shape :  torch.Size([32, 70])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[  287,    10, 12003,  ...,   172,   939,  2037],\n",
       "         [    4,   318,    47,  ...,    14,    47,    58],\n",
       "         [   75,  2542,     9,  ...,  2610,  5270,    36],\n",
       "         ...,\n",
       "         [ 1589, 49007,  3809,  ...,    42,     6,   213],\n",
       "         [   16,  2679, 49069,  ...,    39, 37390,   455],\n",
       "         [    2,     0,   272,  ...,     8,  6906,     9]]),\n",
       " tensor([[   10, 12003,  1294,  ...,   939,  2037,    41],\n",
       "         [  318,    47,   657,  ...,    47,    58,  4441],\n",
       "         [ 2542,     9,   141,  ...,  5270,    36,    90],\n",
       "         ...,\n",
       "         [49007,  3809, 48709,  ...,     6,   213,  1183],\n",
       "         [ 2679, 49069,  3809,  ..., 37390,   455,     9],\n",
       "         [    0,   272,  8508,  ...,  6906,     9,  1133]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = data_lm.one_batch()\n",
    "print('Batch shape : ',test_one_batch[0].shape)\n",
    "test_one_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize model\n",
    "As mentioned [here](https://github.com/huggingface/transformers#models-always-output-tuples), every model's forward method always outputs a tuple with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits.  One way to access them is to create a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel_Encoder(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel_Encoder,self).__init__()\n",
    "        self.transformer = transformer_model.roberta\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                attention_mask = attention_mask)[0]   \n",
    "        return ([logits],[logits])\n",
    "    # this function is added because fastai `learner.lr_find()` will call it\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pretrained weights for RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 50265,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the configuration of language model\n",
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = transformer_tokenizer.vocab_size\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel_Encoder(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel_Encoder(\n",
       "  (transformer): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(model, split_on:SplitFuncOrIdxList)->None:\n",
    "    \"Split the model at `split_on`.\"\n",
    "    if isinstance(split_on,Callable): split_on = split_on(self.model)\n",
    "    layer_groups = split_model(model, split_on)\n",
    "    return layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50265, 768, padding_idx=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = custom_transformer_model.transformer.embeddings.word_embeddings\n",
    "enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our decoder will share the weights of the embedding layer\n",
    "This is to convert the 768 feature dimension back to probability of our 50265 vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-construct decoder using FastAI LinearDecoder\n",
    "\n",
    "decoder = LinearDecoder(transformer_tokenizer.vocab_size, \n",
    "                        n_hid=768, \n",
    "                        output_p=0.1,\n",
    "                        tie_encoder=enc,\n",
    "                        bias=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDecoder(\n",
       "  (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  (output_dp): RNNDropout()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): CustomTransformerModel_Encoder(\n",
       "    (transformer): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialRNN(custom_transformer_model, decoder)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(language_model_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm = LanguageLearner(data_lm, \n",
    "                           model,\n",
    "#                            split_func=tfmer_lm_split,\n",
    "                           opt_func = CustomAdamW)\n",
    "learn_lm.callbacks.append(ShowGraph(learn_lm))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "# if use_fp16: learn_lm = learn_lm.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDecoder(\n",
       "  (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  (output_dp): RNNDropout()\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.model[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer grouping\n",
    "\n",
    "FastAI uses layer grouping for primarily Three objectives:\n",
    "1. discrimilative learning rate\n",
    "2. gradual unfreezing\n",
    "3. saving `state_dict` for certain parts of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For roberta-language-model\n",
    "\n",
    "list_layers = [\n",
    "              [learn_lm.model[0].transformer.encoder.layer[0],\n",
    "              learn_lm.model[0].transformer.encoder.layer[1],\n",
    "              learn_lm.model[0].transformer.encoder.layer[2]],\n",
    "              [learn_lm.model[0].transformer.encoder.layer[3],\n",
    "              learn_lm.model[0].transformer.encoder.layer[4],\n",
    "              learn_lm.model[0].transformer.encoder.layer[5]],\n",
    "              [learn_lm.model[0].transformer.encoder.layer[6],\n",
    "              learn_lm.model[0].transformer.encoder.layer[7],\n",
    "              learn_lm.model[0].transformer.encoder.layer[8]],\n",
    "              [learn_lm.model[0].transformer.encoder.layer[9],\n",
    "              learn_lm.model[0].transformer.encoder.layer[10]],\n",
    "              [learn_lm.model[0].transformer.encoder.layer[11],\n",
    "              learn_lm.model[0].transformer.pooler],\n",
    "              [learn_lm.model[0].transformer.embeddings,\n",
    "              learn_lm.model[1]]\n",
    "              ]\n",
    "\n",
    "# list_layers = [learn_lm.model[0],\n",
    "#               learn_lm.model[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 6 groups\n",
      "[Sequential(\n",
      "  (0): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "  (1): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "  (2): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "  (1): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "  (2): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "  (1): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "  (2): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "  (1): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "  )\n",
      "  (1): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1)\n",
      "  )\n",
      "  (1): LinearDecoder(\n",
      "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
      "    (output_dp): RNNDropout()\n",
      "  )\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "learn_lm.split(list_layers)\n",
    "num_groups = len(learn_lm.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learn_lm.layer_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the model is split into two part Encoder and classifier which enables us to save just the encoder weights later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  311,     8,  8613,  ...,   133, 17161,  2050],\n",
       "         [    5,   230, 10504,  ...,  1469,  1873,   463],\n",
       "         [  172,     6,    45,  ...,    38,  1017,   450],\n",
       "         ...,\n",
       "         [  312,  7150,   354,  ...,  4318,   388,   322],\n",
       "         [   42,  9215,   409,  ..., 29342,   219,  3246],\n",
       "         [ 3199,   269,  3829,  ...,    15,    25,    10]]),\n",
       " tensor([[    8,  8613,    10,  ..., 17161,  2050,   113],\n",
       "         [  230, 10504,  7875,  ...,  1873,   463,   197],\n",
       "         [    6,    45,   379,  ...,  1017,   450,    69],\n",
       "         ...,\n",
       "         [ 7150,   354,  4133,  ...,   388,   322,    20],\n",
       "         [ 9215,   409,    31,  ...,   219,  3246,     6],\n",
       "         [  269,  3829,    42,  ...,    25,    10,   809]]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the model and turn it to mixed-precision mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 3.63E-03\n",
      "Min loss divided by 10: 5.75E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.freeze()\n",
    "\n",
    "learn_lm.lr_find()\n",
    "learn_lm.recorder.plot(skip_end=5,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 3:05:54<46:28]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.419995</td>\n",
       "      <td>0.234654</td>\n",
       "      <td>0.966060</td>\n",
       "      <td>46:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.229334</td>\n",
       "      <td>0.108167</td>\n",
       "      <td>0.984882</td>\n",
       "      <td>46:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.186958</td>\n",
       "      <td>0.095526</td>\n",
       "      <td>0.986432</td>\n",
       "      <td>46:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162994</td>\n",
       "      <td>0.090002</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>46:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9747' class='' max='10702', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      91.08% [9747/10702 40:28<03:57 0.1572]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3.63E-03\n",
    "learn_lm.fit_one_cycle(5, lr, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): CustomTransformerModel_Encoder(\n",
       "    (transformer): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the encoder of the language model and save it's encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn_lm.model)[0].transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'learn_lm_encoder_IMDB'\n",
    "torch.save(encoder.state_dict(), learn_lm.path/learn_lm.model_dir/f'{name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/models/learn_clas_unfreed_second.pth'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models/fit_freezed_5_epochs.pth'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models/fine_tuned_lm_enc.pth'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models/tmp.pth'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models/learn_clas_unfreezed_third.pth'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models/learn_clas_unfreezed_final.pth'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models/learn_lm_encoder_IMDB.pth'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models/fine_tuned_lm.pth'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models/learn_clas_freezed.pth')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'models').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataBunch for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can play around with the batch_size as long as the GPU can take it\n",
    "bs = 48\n",
    "data_clas = (TextList.from_folder(path, processor=transformer_processor)                         # specify the path\n",
    "           .filter_by_folder(include=['train','test'])# exclude other folders\n",
    "           .split_by_folder(valid='test')                 #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "           .label_from_folder(classes=['neg', 'pos'])                    #label them all with their folders\n",
    "           .databunch(bs=bs))                                 # convert to databunch for the learner later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : <s>\n",
      "[SEP] token : </s>\n",
      "[PAD] token : <pad>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / train / pos / 11 86 2 _ 10 . txt &lt;/s&gt;</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / train / pos / 12 06 1 _ 10 . txt &lt;/s&gt;</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / train / neg / 12 05 6 _ 4 . txt &lt;/s&gt;</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / train / neg / 8 98 3 _ 1 . txt &lt;/s&gt;</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / train / pos / 12 08 2 _ 8 . txt &lt;/s&gt;</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 0\n",
      "[SEP] id : 2\n",
      "[PAD] id : 1\n",
      "Batch shape :  torch.Size([48, 27])\n",
      "tensor([[    0,  1589,  8361,  ...,     4, 46795,     2],\n",
      "        [    0,  1589,  8361,  ...,     4, 46795,     2],\n",
      "        [    0,  1589,  8361,  ...,     4, 46795,     2],\n",
      "        ...,\n",
      "        [    1,     0,  1589,  ...,     4, 46795,     2],\n",
      "        [    1,     0,  1589,  ...,     4, 46795,     2],\n",
      "        [    1,     0,  1589,  ...,     4, 46795,     2]])\n"
     ]
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = data_clas.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                attention_mask = attention_mask)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = 2\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the encoder's pre-trained weights from the language model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transformer_model.transformer.roberta.load_state_dict(torch.load(learn_lm.path/learn_lm.model_dir/f'{name}.pth', map_location=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(data_clas, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = CustomAdamW, \n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For roberta-base\n",
    "list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "              learner.model.transformer.roberta.encoder.layer[0],\n",
    "              learner.model.transformer.roberta.encoder.layer[1],\n",
    "              learner.model.transformer.roberta.encoder.layer[2],\n",
    "              learner.model.transformer.roberta.encoder.layer[3],\n",
    "              learner.model.transformer.roberta.encoder.layer[4],\n",
    "              learner.model.transformer.roberta.encoder.layer[5],\n",
    "              learner.model.transformer.roberta.encoder.layer[6],\n",
    "              learner.model.transformer.roberta.encoder.layer[7],\n",
    "              learner.model.transformer.roberta.encoder.layer[8],\n",
    "              learner.model.transformer.roberta.encoder.layer[9],\n",
    "              learner.model.transformer.roberta.encoder.layer[10],\n",
    "              learner.model.transformer.roberta.encoder.layer[11],\n",
    "              learner.model.transformer.roberta.pooler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 14 groups\n",
      "[Sequential(\n",
      "  (0): Embedding(50265, 768, padding_idx=1)\n",
      "  (1): Embedding(514, 768, padding_idx=1)\n",
      "  (2): Embedding(1, 768)\n",
      "  (3): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (4): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=2, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "learner.split(list_layers)\n",
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learner.layer_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('untrained_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.load('untrained_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.freeze_to(-1)\n",
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 6.31E-07\n",
      "Min loss divided by 10: 1.00E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end = 10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.639405</td>\n",
       "      <td>0.593255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.615712</td>\n",
       "      <td>0.562045</td>\n",
       "      <td>0.695040</td>\n",
       "      <td>0.304960</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.593364</td>\n",
       "      <td>0.559695</td>\n",
       "      <td>0.500280</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.588994</td>\n",
       "      <td>0.500404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.577490</td>\n",
       "      <td>0.503677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, 5e-4,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old ULMFiT code for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Padding_idx must be within num_embeddings",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-e950d9b385f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# the drop_mult decide the percentage of dropout to use in relation to the combination used in the original paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn_lm_AWD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_model_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mlanguage_model_learner\u001b[0;34m(data, arch, config, drop_mult, pretrained, pretrained_fnames, **learn_kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            pretrained_fnames:OptStrTuple=None, **learn_kwargs) -> 'LanguageLearner':\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m\"Create a `Learner` with a language model from `data` and `arch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_mult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_model_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_lm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlearn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mget_language_model\u001b[0;34m(arch, vocab_sz, config, drop_mult)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mtie_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'tie_weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out_bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'init'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtie_weights\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hid_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtie_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mold_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/text/models/awd_lstm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token, hidden_p, input_p, embed_p, weight_p, qrnn, bidir)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_hid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbidir\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddingDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqrnn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Padding_idx must be within num_embeddings"
     ]
    }
   ],
   "source": [
    "# the drop_mult decide the percentage of dropout to use in relation to the combination used in the original paper\n",
    "learn_lm_AWD = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "As we can see below, when we create `TextDataBunch` a  `vocab` property is created simultaneously. <br>\n",
    "It's worth pointing out that, for `index-to-strings` and `strings-to-index` we have a different length. This is primarily because that there are some words that appear infrequently so that it's not effcient for them to occupy one token. What we do is to map all of these low frequency words to `xxunk`. We can ditermine the `min_freq` in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = data_lm.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35055"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[\"stingray\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[\"happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.itos[vocab.stoi['mamamia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_lm.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(60000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ourmodel has two parts, the AWD_LSTM base architecture and the linear classifier\n",
    "learn_lm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on `drop_mult`\n",
    "From the original [AWD_LSTM paper](https://arxiv.org/pdf/1708.02182.pdf) the authors applied several effective techniques.<br>\n",
    "\n",
    "**DropConnect** was implemented in the architecture in that weight matrices are *dropped* before the *forward* and *backward* pass.<br>\n",
    "\n",
    "**Variational dropout**. In standard dropout, a new binary dropout mask is sampled each and every time the dropout function is called. **Variational dropout** only samples a *dropout mask* upon the first call and then will repeatedly use that *locked dropout* mask for all repeated connections within the forward and backward pass.<br>\n",
    "\n",
    "The values used for *dropout on the word vectors*, the *output between LSTM layers*, the *output of the final LSTM layer*, and *embedding dropout* were (0.4, 0.3, 0.4, 0.1), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Encoder is the first layer of the AWD_LSTM, which is also known as the `embedding layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 400])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = learn_lm.model[0].encoder\n",
    "enc.weight.size()  # 400 is the embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall that 60000 is the vocab size of our language model vocabulary\n",
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before training\n",
    "Let's try to use this model(only pre-trained with wiki-text) to generate fake movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = 'The color of the sky is'\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the sky is often changed from black to blue , to give it a more light color . The color is derived from the colours of one of the sky planets and the blue sky . The bird 's colour is\n",
      "\n",
      "The color of the sky is a reference to the thin red hair of the Earth . The physical presence of the moon in the sky and the dark sky in the dark , and the so - called Earth - like sky\n"
     ]
    }
   ],
   "source": [
    "# Note that the 'temperature' denote the randomness we adopt when pick next words\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the sky is a matter of controversy , as the Sun is not a white sky , but a white sky . The Sun is a dark , dark , dark , dark , dark , dark , dark ,\n",
      "\n",
      "The color of the sky is a matter of debate , and the International Union of Red and White Stars ( NAACP ) has been the most popular group of the American public . The American\n",
      "\n",
      "The color of the sky is a matter of controversy , as the Sun has been described as a \" dark , dark , dark , dark , dark , dark , dark , dark , dark , dark , dark , dark , dark\n"
     ]
    }
   ],
   "source": [
    "# If 'temperature'  set to super low, there will be almost no randomness\n",
    "N_SENTENCES = 3\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.05) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hate this movie so much it does not last for a single , less weekly , or just a few more pages of a book , so it can be seen as Lily Allen 's second novel The Spirit of\n",
      "\n",
      "I hate this movie so much that i think i would be thinking about it . The greatest reason why i wanted to make a movie about a movie was that you would not let it go , because it was not a chance to\n",
      "\n",
      "I hate this movie so much that i can ' t do that . It could make you want to see what is right . But i don ' t hope to see what the right thing can do , and as many as\n"
     ]
    }
   ],
   "source": [
    "# Change TEXT\n",
    "TEXT = 'I hate this movie so much'\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc(LanguageLearner.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning a language model\n",
    "We can use the `data_lm` object we created earlier to fine-tune a pretrained language model. \n",
    "Here we will be using a pre-trained `AWD-LSTM` architecture theat is available in FastAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn_lm.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot function attached to lr_finder\n",
    "# Note that we get a smoothened version where `skip_start` and `skip_end` decide howmuch to trim-off from start or end\n",
    "\n",
    "def plot(self, skip_start:int=10, skip_end:int=5, suggestion:bool=False, return_fig:bool=None,\n",
    "             **kwargs)->Optional[plt.Figure]:\n",
    "        \"Plot learning rate and losses, trimmed between `skip_start` and `skip_end`. Optionally plot and return min gradient\"\n",
    "        lrs = self._split_list(self.lrs, skip_start, skip_end)\n",
    "        losses = self._split_list(self.losses, skip_start, skip_end)\n",
    "        losses = [x.item() for x in losses]\n",
    "        if 'k' in kwargs: losses = self.smoothen_by_spline(lrs, losses, **kwargs)\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.plot(lrs, losses)\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_xlabel(\"Learning Rate\")\n",
    "        ax.set_xscale('log')\n",
    "        ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
    "        if suggestion:\n",
    "            try: mg = (np.gradient(np.array(losses))).argmin()\n",
    "            except:\n",
    "                print(\"Failed to compute the gradients, there might not be enough points.\")\n",
    "                return\n",
    "            print(f\"Min numerical gradient: {lrs[mg]:.2E}\")\n",
    "            ax.plot(lrs[mg],losses[mg],markersize=10,marker='o',color='red')\n",
    "            self.min_grad_lr = lrs[mg]\n",
    "            ml = np.argmin(losses)\n",
    "            print(f\"Min loss divided by 10: {lrs[ml]/10:.2E}\")\n",
    "        if ifnone(return_fig, defaults.return_fig): return fig\n",
    "        if not IN_NOTEBOOK: plot_sixel(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3zV1f3H8dcnCUkIhBBI2CPsvSOouHEvHEXFUbW2jlalWrXVDhXrr9rlrLNWrXvg1oqC4gAUE5bsGSCBhBCSEMgg4/z+uBe9YkIC3J338/G4D+79fs+993O4ST73e6Y55xAREfG3mFAHICIi0UkJRkREAkIJRkREAkIJRkREAkIJRkREAiIu1AH4S1pamsvIyAh1GCIiESU7O3ubcy49EK8dNQkmIyODrKysUIchIhJRzGxDoF5bTWQiIhIQSjAiIhIQSjAiIhIQSjAiIhIQSjAiIhIQSjAiIhIQSjAiIhIQSjAiIhFsWnYuL83bGOow6qUEIyISwV7N2sSb8/NCHUa9lGBERCJY/o5KOqYkhjqMegU8wZhZrJktMLP36jnXw8w+9Z5fbGaneo9nmFmFmS303h4LdJwiIpHGOUd+aSWdwzTBBGMtsinAcqBNPef+ALzqnHvUzAYDHwAZ3nNrnXMjgxCfiEhEKq2opqqmjo5twjPBBPQKxsy6AacB/26giOP7xJMCbA5kPCIi0SR/RyUAnZpjggHuB24B6ho4fwdwsZnl4rl6uc7nXC9v09lnZnZkfU82syvNLMvMsgoLC/0Zt4hI2Msv9SaYlIQQR1K/gCUYMzsd2Oqcy95HscnAM865bsCpwHNmFgNsAXo450YBNwIvmtmPmticc0845zKdc5np6QHZzkBEJGztSTDNsYlsPHCmmeUALwPHmdnze5W5AngVwDk3F0gE0pxzVc65Iu/xbGAt0D+AsYqIRJw9TWQdkptZgnHO3eqc6+acywAuAD5xzl28V7GNwAQAMxuEJ8EUmlm6mcV6j/cG+gHrAhWriEgkKthRSVrrBOLjwnPGSdB3tDSzqUCWc+4d4DfAk2Z2A54O/8ucc87MjgKmmlkNUAtc7ZzbHuxYRUTCWX5pZdj2v0CQEoxzbhYwy3v/Tz7Hl+FpStu7/DRgWjBiExGJVFtKK+mW2jLUYTQoPK+rRESkUQU7KsO2gx+UYEREIlJldS3F5dVhOwcGlGBERCLS1h1VAHQK02ViQAlGRCQifTeLXwlGRET8aUtpBRC+y8SAEoyISEQq8F7BhOtS/aAEIyISkfJLq0iKjyU5IejTGZtMCUZEJAIV7KikU0oiZhbqUBqkBCMiEoHyd1SGdf8LKMGIiESk/FIlGBER8bO6OueZxR/GHfygBCMiEnGKdu2mps7pCkZERPzruyHKSjAiIuJPW7w7WXZWE5mIiPhTJCwTA0owIiIRp6C0ktgYI611+G42BkowIiIRJ39HJemtE4iNCd9JlqAEIyIScSJhiDIowYiIRJwtpZV0DvMRZKAEIyIScQpKK8O+gx+UYEREIsquqhrKqmrCfg4MKMGIiESU74coh/cIMlCCERGJKAWlkTGLH5RgREQiyp5Z/OG+DhkowYiIRJRImcUPSjAiIhGlYEclbRLjSIoP362S91CCERGJIPkRMkQZlGBERCJK/o7KiOjgByUYEZGIsrmkki4pLUMdRpMowYiIRIjK6lq27ayia6oSjIiI+NGeIcpd2irBiIiIH+UVVwDQVQlGRET8Ka+kHIBuaiITERF/yiupxCwyJlmCEoyISMTIK66gY3IiLWIj4093ZEQpIiLklZRHzAgyCEKCMbNYM1tgZu/Vc66HmX3qPb/YzE71OXerma0xs5VmdlKg4xQRCXd5JRUR08EPwbmCmQIsb+DcH4BXnXOjgAuARwDMbLD38RDgZOARM4sNQqwiImGpts6RX1qpK5g9zKwbcBrw7waKOKCN934KsNl7fyLwsnOuyjm3HlgDjA1krCIi4aywrIrqWhcxc2Ag8Fcw9wO3AHUNnL8DuNjMcoEPgOu8x7sCm3zK5XqP/YCZXWlmWWaWVVhY6LegRUTCzXdDlJVgwMxOB7Y657L3UWwy8IxzrhtwKvCcmcUAVk9Z96MDzj3hnMt0zmWmp6f7JW4RkXCUV+KZxR9JTWSB3FBgPHCmt+M+EWhjZs875y72KXMFnj4WnHNzzSwRSMNzxdLdp1w3vm8+ExFpdvbM4lcTGeCcu9U51805l4Gnw/6TvZILwEZgAoCZDcKTiAqBd4ALzCzBzHoB/YB5gYpVRCTc5ZWUk9KyBa0Twn+jsT2CHqmZTQWynHPvAL8BnjSzG/A0gV3mnHPAUjN7FVgG1AC/cs7VBjtWEZFwkVccWUOUIUgJxjk3C5jlvf8nn+PL8DSl1fecu4G7gxCeiEjY21xSSY/2SaEOY79oJr+ISJhzzkXcJEtQghERCXs7KmrYWVWjBCMiIv6VV+LdByaChiiDEoyISNjbk2AiaYgyKMGIiIS9vGLPLH41kYmIiF/llVSQEBdDWuv4UIeyX5RgRETC3OaSSrq2bYlZfatohS8lGBGRMJdbUhFx/S+gBCMiEvYicRY/KMGIiIS1yupatu2sirghyqAEIyIS1raUepbpVxOZiIj41Z5l+tVEJiIifvXdTpZqIhMREX/KK6nEDDqlJIY6lP2mBCMiEsbyiivomJxIi9jI+3MdeRGLiDQjeSXlETmCDJRgRETC2p5Z/JFICUZEJEzV1NaxuaQiIjv4QQlGRCRs5RZXUFPnyEhrFepQDogSjIhImFpftAuAXkowIiLiTznbPAkmo70SjIiI+FHOtl20ToiLuH1g9lCCEREJU+u27aJXWquI2wdmDyUYEZEwlVO0K2I7+EEJRkQkLO2uqSOvuIJe7ZNCHcoBU4IREQlDG7eXU+fQFYyIiPjX+m2RPUQZlGBERMJSjhKMiIgEwvqiXbRNakHbpMgcogxKMH5RtLOKBRuLqa6tC3UoIhIlcrbtitgJlnvEhTqASFdaUc2kx+eyrtAzIerQ3u05sl8axw/uGLEroIpI6OVs28WhvduHOoyDoiuYg1BTW8d1Ly1gY1E5fzhtEGeM6MLKgh3c/s5STvznZ2wsKg91iCISgSp217K5tDKiR5CBrmAOyt0fLOfzVYXcc84wLhjb47vjK/J38JNH53Lbm9/y3BVjI3YWroiExobt3jXIIjzB6ArmAL00byNPz87h8vEZP0guAAM7teG3Jw/gyzXbmDY/L0QRikik+m4EWYT3wSjBHIA5a7fxx7eWcFT/dH5/6qB6y1w0rieZPVO5671lFJZVBTlCEYlk67d5mtcz0iJ3Fj80McGYWR8zS/DeP8bMrjeztoENLfxU19bxwIzV/PSpefRsn8RDk0cRF1v/f2FMjHHPucOo2F3Lne8uDXKkIhLJ1m/bSVrrBJITW4Q6lIPS1CuYaUCtmfUFngJ6AS825YlmFmtmC8zsvXrO3WdmC723VWZW4nOu1ufcO02MM2BW5O/grH/N5r4ZqzhteGdev/pwUlru+8Pv2yGZa4/ry3uLtzBjWQHOObbv2s2iTSVkbyjGORek6EUkkuRsK6dXhF+9QNM7+eucczVmdjZwv3PuITNb0MTnTgGWA232PuGcu2HPfTO7Dhjlc7rCOTeyie8RUM/MXs/dHywnpWULHrt4DCcP7dTk5159dB/eX7yF615aQGyMsbOq5rtzfzx9MFcc0SsQIYtIBFtftItj+qeHOoyD1tQEU21mk4FLgTO8xxq9djOzbsBpwN3AjY0Unwzc3sR4gubb3FLufG8Zxw7owN8njaBdq/2bVRsfF8N954/k4U9X0yE5ke7tkuie2pJXvtnEPf9bzrhe7RjaNSVA0TdsY1E5Hy3L5+JDe5LYIjbo7y8i9dtZVUNhWRW90iO7gx+anmAuB64G7nbOrTezXsDzTXje/cAtQPK+CplZTzzNbp/4HE40syygBrjHOfdWPc+7ErgSoEePHnufPmh1dY4/vr2E9q3iue/8kY02iTVkcJc2PHLRmB8cOySjHac88AXXv7SAd687glYJwRsxPndtEde8kE1JeTUfLyvgiZ9mHnDdRMS/omUEGTSxD8Y5t8w5d71z7iUzSwWSnXP37Os5ZnY6sNU5l92Et7gAeN05V+tzrIdzLhO4ELjfzPrUE9cTzrlM51xmerr/Lydfz85l4aYSfnfKIL//AU71Jq31Rbu4453gDQJ4ad5GLnnqa9q3iucPpw1i/sZizn98LgU7KoMWg4g0bM8qypE+BwaaPopslpm1MbN2wCLgaTP7ZyNPGw+caWY5wMvAcWbW0FXPBcBLvgecc5u9/64DZvHD/pmAKy2v5p4PVzCmZyrnjOoakPc4rE97rj22L69l5/L2wsDOl6mpreOOd5Zy6xvfMr5vGm/+ajw/P7I3T116CBu3l3POI3NYV7gzoDGISOP2XMFE+jpk0PRRZCnOuR3AOcDTzrkxwPH7eoJz7lbnXDfnXAaeBPKJc+7ivcuZ2QAgFZjrcyzVZ1h0Gp5ktayJsfrFPz5eSUn5bqZOHEJMTOBm4k+Z0I8xPVP5/ZtLWJlfFrD3+ftHq3hmTg5XHNGLpy7NpI13+ONR/dN5+cpDqayu5SePzdXyNiIhtr5oF53aJNIyPvL7RpuaYOLMrDNwHvCj4cb7w8ymmtmZPocmAy+7H47ZHQRkmdki4FM8fTBBSzBLN5fy/FcbuPjQngzpEtgO+LjYGB64YCQt42P5yWNzmLu2qN5yBTsqKS2vPqD32LS9nP98uZ6fjOnGH08f/KO5O8O7teW1qw+juqaOW99crOHTIiGUs21XRO8B46upPctTgenAbOfcN2bWG1jd1Ddxzs3C08yFc+5Pe527o57yc4BhTX19f3LOcfvbS0lNiuc3JwwIynt2S03izV8ezmVPf8Ol/5nH3yYNZ+JIT7Pcpu3l3DdjFW8tyMMBQ7q04fA+aRzWuz2H9WnfpBFg93y4gtgY4+aTGq5P7/TW/PaUgfzhrSW8np3LpMzu/qqeiOyH9dt2cfLQzqEOwy+alGCcc68Br/k8XgecG6igQmnWykKyNhRz99lDSUkK3siqbqlJTLv6cK58LospLy8kZ1s5RbuqeGneRsyMy8f3onVCHHPXFfHM7Bye+HwdY3qm8uIvxpEQ13CSyd5QzPuLtzBlQj86tkncZwwXju3B2wvz+PP7yzlmQAfSkxP8XU0R2YeS8t0Ul1dHxSRLaHonfzcze9PMtppZgZlN885xiSrOOe6fuZqubVsyaUzwv8GnJLXgv1eM5YwRXbhvxipe/HojkzK789nNx/DH0wdzwwn9efWqw1h0+4n85ZxhZG8o5o53Gm45dM7x5/eX0SE5gauO7t3o+8fEGH85ZzgVu2u5o57lberq1HQmEkh7+mH7d9znzI6I0dQmsqfxLA0zyfv4Yu+xEwIRVKh8tqqQRZtKuPvsocTHhWYd0IS4WB44fyQnDu7IsK4p9Q5VbBkfy+SxPdi0vZxHZq1lWNcULhz343lA7y3ewoKNJfz1J8NJim/aR923Q2uuO64v//h4FWeNLOD4QR3I3lDMi/M28sG3W/jpYRncespAbUEgEgCrCjwJZkCn5pVg0p1zT/s8fsbMfh2IgELFOccDM1fTJSUxJFcvvmJijDNGdGm03G9OHMCyLTu4/Z0lDOjUmjE92313rrK6lns/XMGgzm04d/T+XWxedXQf3lu8hdve/Ja/ftiC1Vt30johjuFd2/LE5+uIjTFuOWmAkoyIn60sKCM5MY5OjTRnR4qmfk3fZmYXexeujDWzi4H6hztFqC/XbGPBxhKuObZvyK5e9ldsjPHA+aPo0rYlVz8/n8W5JXy0NJ8HZqzm8qe/Ibe4gj+cNojY/RxmHR8Xwz3nDqO0opqkhDjuPXcYX982gVeuOpQLx/Xg0VlreWBmk8d4iEgTrcrfycBOyVHz5a2pVzA/Ax4G7gMcMAfP8jFRwTnHAzNW0zklkfMyI6trKSWpBU9cksnZj8zmzIdnA2DmmaR1/XF9Gd837YBed1SPVBbffuKPRqn9eeJQdtfUcf+M1cTHxfDLY/oedB1ExPN3aEX+jia1XkSKpo4i2wj4zl3B20R2fyCCCrY5a4vI2lDM1IlD9jkiK1wN6JTM61cfzuLcEgZ0SmZAp+Qm97nsS31DoGNijHvPHU51bR1//XAlhWVV/HpC/6COuBOJRgU7qthRWRM1/S/Q9CuY+txIFCSYPVcvHdskcF4Ez/0Y3KUNg7v8aEeEgIiNMf4xaQTJiXE8MyeHNxfkMWVCPy4a1zNimhcb4pyjqqZOK0xL0K0siK4RZHBwWyZHRSNhTlE5CzYVc83RffRHZT/Excbw57OG8f51RzK0Swp3vruME+/7jC9WF4Y6tANWWV3LtS8tYNgd0/n1ywtYsLE41CFJM7IyfwcAA5RgAE9fTMTrldaKWTcfywVj/b/cf3MwuEsbnrtiLE9ffgixMcal/5nH07PXh+1yM9Oyc/nnRyvZvmv3D45v21nF5Ce/4oNvtzBhYEdmLN/K2Y/MYeK/ZvP2wrywrY9Ej5X5O+mQnEDqfu45Fc722URmZmXUn0gMaBmQiEKga9uoqUpImBnHDujAuF7t+PXLC7nz3WWsLdzJ7WcMoUVs+DSZPTc3hz++7ZlA+tSX67lsfAa/OLI3hWVVXP7MN2zbWcWjF43m5KGd2VlVw7TsXJ6dk8OUlxfy0dIC7v3JcFoHcd8eaV5WFZRFVf8LNJJgnHPRVVsJqKT4OB67eAz3Tl/B45+tY0NROQ9fODosNjN74esN/PHtpZwwuCM3ntCfR2at5ZFZa3l2zgYMSIyP5ZUrD2NE97YAtE6I49LDM7jk0J48+cU67v1wBSsLynj8kjH0SW8d2spI1Kmtc6zeWsbF43qGOhS/Cp+vlxIVYmKMW08ZxF9/Mpyv1hVx5sNf8k3O9pDG9NK8jfz+zSVMGNiBf104mkGd2/DQ5FFM//VRHN0/nQGdknnrV+O/Sy6+YmKMq47uw/NXjGP7rt1MfHg2Hy7JD0EtJJpt3F5OZXUd/aPsCsaipW05MzPTZWVlhToM8ZGVs50bX13EpuJyfja+FzefNOAHAymqa+vI2baLnKJyNhTtIqdoFzsqaji0d3smDOrQ6OKcjamurePZOTn8+f3lHDsgnccuGXNQw9A3l1RwzQvzWbSphNE92nJeZndOG96Z5MTQX6FJZPtwST5XP5/N2w180QkkM8v27h7s/9dWgpFA2lVVw70fruC/czfQO60Vl43PYM3WnSzOLWXZlh3srqn7rmybxDhaxsdSsKMKgKFd2zBhYEfOP6Q7Xfajn6yqppbXs3N5dNZacosrOG5gBx65aLRfRglW1dTy3zkbeCVrE2u27qRli1hOGdaJM4Z3afL2CSJ7e3Dmau6bsYqld57klzls+0MJpgmUYMLbnDXbuPn1xeSVVNA6IY4hXdowvFsKg7u0oVdaazLaJ9E2KR7nHGu27mTG8q18sqKA7A3FxJhnbbafH9lrnxvAOed4cd5GHpq5hvwdlYzs3pbrJ/Tl2AEd/L70hnOOhZtKeDUrl/cWbaasqoZW8bEcM6ADJw7pyElDOinZSJP96oX5LNlcymc3Hxv091aCaQIlmPBXWV1LwY5KuqcmNXkb6tzicp6encPL8zaya3ctR/RN44YT+v1gYU+AHZXV3PzaIqYvLSCzZypTju/HEX3TgrKmU1VNLXPXFjF9aQEfLytg284qhnVN4YmfjqFzikYoSuOO/+dn9EprxZM/Dcjf+X1SgmkCJZjoVlpezYvzNvLUl+vZtrOKk4d04paTB9A7vTVLN5fyyxfmk1tcwa2nDOSKI3qFbLHAujrH9KX53PTaIpIS4njikjGM6pEaklgkMlTV1DL4T9O55ug+3LSPXWcDJZAJRoP6JSKkJLXgmmP6cOnhPfn3F+t5/LO1fLy8gJOHdGLG8gLaJrXg5SsP5ZCMdo2/WADFxBinDOtMnw6t+fmzWZz/xFfce+4wzh4VWYuoSvCsK9xFbZ2LuhFkoAQjESYpPo7rJ/Rj8tgePDhzNS/O28ihvdvxwAWjSGsdPls89+/oGfr8yxeyueGVRbyencshGe0Y0zOVkd3bauSZfGfPLpYDlWBEwkN6cgJ3nTWU35zYnzaJLZrcpxNM7VrF89wV43ho5mo+WlbAAzNX45xnO4UR3dpy8tBOnDyk03e7lpZVVjN7zTZmrSykorqWK47oxfBuwR2yKsG3sqCMFrFGRvsf714b6dQHIxIkZZXVLNxUQlZOMZ+u3Mri3FLA8801pWULsjcUU1PnSE6Iwwx2VNYwYWAHphzfT4kmil3xjGdzwOk3HBWS91cfjEgUSE5swZH90jmyXzo3nNCf3OJyPlpawIdL89m1u4ZfHNWbY/qnM7pnKpXVtfx37gae/GIdZz48mxMHd+Sf54/UWmhRaGVBGaOjdCCIrmBEwlhZZTXPzM7h/pmrGdMzlWcvH0vLeM2viRY7q2oYevt0bj5pAL86NjS7wwbyCkZrkYmEseTEFlw3oR//PG8E3+Rs58rnsqisrg11WOIny7dE3x4wvpRgRCLAxJFd+eu5w/li9TaufXH+D5bYkci1aFMJAMO7N7xCRSRTghGJEJMyu3PXWUOZsXwrv35lAdW1SjKRblFuKV3btqRD8sEt7Bqu1GMoEkEuObQnVdW1/Pn95eyumc/DF47SmmcRbNGmEoZ3i86rF9AVjEjE+fmRvZk6cQgzlhdw+dPfsLOqJtQhyQHYvms3G7eXB315/mBSghGJQD89LIP7zx/JvJztXPjkV2zftTvUIcl+WpTr6X8ZEcVznJRgRCLUWaO68sQlY1iZX8akx+bwxvxctu2sCnVY0kSLN5ViBsOiuIlMfTAiEWzCoI48+7OxTHl5ATe+usjzB6trCscO6MDPxvciJUlrnoWrRbkl9OvQOqonz+oKRiTCHdq7PXN/N4F3rz2CG4/vT4vYGB76ZDVXPPuN5syEKeccizaVRHXzGCjBiESFmBhjWLcUrpvQj2nXHM5Dk0eTtaGY37y6iLq66FitI5rkFldQtGt3VHfwg5rIRKLSacM7s7lkEHd/sJyuqS257dRBoQ5JfOzp4B+pBCMikejnR/ZiU3E5T3y+ju6pLbnksIxQhyReizaVEB8Xw4Ao3APGV8CbyMws1swWmNl79Zy7z8wWem+rzKzE59ylZrbae7s00HGKRBsz4/YzhnD8oA7c/s5SPllREOqQxGvRplKGdGlDi9jo7qUIRu2mAMvrO+Gcu8E5N9I5NxJ4CHgDwMzaAbcD44CxwO1mFp3rWYsEUGyM8eDkUQzpksKUlxayrnBnqENq9mpq6/g2rzTqO/ghwAnGzLoBpwH/bkLxycBL3vsnAR8757Y754qBj4GTAxOlSHRLio/jsUvG0CIuhiufy9bM/xBbU7iTiuraqO9/gcBfwdwP3ALsc1U+M+sJ9AI+8R7qCmzyKZLrPbb38640sywzyyosLPRPxCJRqGvbljw8eRTrCndy06uLiJZ9oCLRnhWUo30EGQQwwZjZ6cBW51x2E4pfALzunNszaL++DdZ/9BvhnHvCOZfpnMtMT08/iGhFot/hfdO49ZRBfLg0n0dmrQ11OM3Wwk2ltEmMI6N9UqhDCbhAXsGMB840sxzgZeA4M3u+gbIX8H3zGHiuWLr7PO4GbA5EkCLNyc+P7MUZI7rw949WMmvl1lCH0ywt2lTCiO5tMavve3R0CViCcc7d6pzr5pzLwJNAPnHOXbx3OTMbAKQCc30OTwdONLNUb+f+id5jInIQzIx7zx3GgI7JTHl5IZu2l4c6pGalYnctKwvKmkX/C4RgJr+ZTTWzM30OTQZedj6Nws657cBdwDfe21TvMRE5SEnxcTx+yRicc1z1XDYVu7WcTLAs3VxKbZ1jeDMYQQZBSjDOuVnOudO99//knHvH59wdzrnf1fOc/zjn+npvTwcjTpHmomf7Vtx/wUiWbdnB79/6Vp3+QTJ/YzEQ/TP494juWT4i0qDjBnZkyoR+vDE/j+e/2hDqcJqF+RtK6NEuifTkhFCHEhRKMCLN2JQJ/Th2QDpT31vG1+uKQh1OVHPOkb2xmDE9m8+ccSUYkWYsJsa4//xRdGnbkslPfsWNry5kQ9GuUIcVlXKLKygsq2J0j+bRPAZKMCLNXkpSC9785Xh+fmRv3l+8hQn/+Ixb31jM5pKKUIcWVfb0v4zWFYyINCftWsVz26mD+PyWY7loXA9ez87lpPs+Z/rS/FCHFjXmbygmKT6WAR2jewVlX0owIvKdjm0SuXPiUGbeeAy90ltx1XPZ/OV/y6mp3edqT9IE8zd6drCMi/IVlH01n5qKSJP1aJ/Ea1cfxkXjevD4Z+u4+Kmv2VpWGeqwIlb57hqWbdnRrDr4QRuOiUgDEuJiufvsYYzukcrv3/qWI+75lIy0JPqkt6Z3eitGdGvLCYM7NoslTw7W4lzPBMvRPZtPBz8owYhII84d041h3VKYlp3L2sJdrMwv46NlBdTWOSaN6cbdZw8jPk6NIfuyp4N/VHddwYiI/ED/jsnceuqg7x7vrqnjX5+u4YGZq9lQVM5jl4yhXav4EEYY3uZvKKZ3eitSm9n/kb52iMh+i4+L4YYT+vPg5FEszC1h4r++ZHVBWajDCkvOOeZvLGF0j+Z19QJKMCJyEM4c0YVXrjyUit11nPPIHD5csiXUIYWdnKJytu/a3ew6+EEJRkQO0qgeqbx97Xh6p7fi6ufnc+e7S9ldo2HNe8zf4J1gqSsYEZH917VtS167+nAuH5/B07NzmPT4XO014zV/YzHJCXH069A61KEEnRKMiPhFfFwMt58xhEcvGs26rTs57cEvePHrjdTWNe+tALI3FDOyR1tiYprfcG4lGBHxq1OGdea9649gYKc23Pbmt5z+0JfMXds8V2ouq6xmVUFZs2weAyUYEQmAnu1b8cpVh/KvC0ezo6KayU9+xdXPZVNYVhXq0IJq0aZS6hzNsoMflGBEJEDMjNOGd2bmb47mphP7M2vVVi57eh47q2pCHVrQfLpyK/GxMYxqRkv0+1KCEZGASmwRy7XH9ePRi8ewIjeMsmQAAA+kSURBVL+Ma57PproZLJ5ZW+d4d9FmjhmQTnJii1CHExJKMCISFMcO6MBfzhnGF6u38dtpi3Euujv/v15XxNayKiaO7BrqUEJGS8WISNCcl9mdLSWV3DdjFV1SWnLTSQNCHVLAvL1wM63iY5kwqEOoQwkZJRgRCarrJ/Qlf0cFD3+6hp7tk5iU2T3UIfldVU0tHyzZwklDO5HYIjbU4YSMmshEJKjMjLsmDuXwPu25/Z2lbCjaFeqQ/G7WykLKKmuadfMYKMGISAjExcbw90kjiI0xbnx1UdRNxnxn4WbSWsczvk/7UIcSUkowIhISXdq25K6JQ8neUMxjn60NdTh+U1ZZzYzlBZw+vEuz2h65Ps279iISUhNHduG04Z25f8Yqlm4uDXU4fvHR0gKqauo4c2SXUIcSckowIhIyZsbdZw0lNSmeG15ZSGV1bahDOmhvLcyje7uWjOrePCdX+lKCEZGQapsUz98mjWBVwU5uf3spdRHcH1NYVsXsNduYOKIrZs1vccu9KcGISMgd3T+d647ryytZm/jTO0siNsm8v3gzdc7T9CeaByMiYeLGE/pTU+d4dJanw3/qmUMjbon7NxfkMbhzG/p1TA51KGFBCUZEwoKZcYt3Zn8kJpk1W8tYlFvKH04bFOpQwoYSjIiEjb2TTF5xBedldueYAR1oGR/eM+LfmJ9HbIxp9JgPJRgRCSt7kkxyYhxPfbGeT1cWkhQfy3EDO3DhuB4c3ict1CH+SF2d480FeRzVL40OyYmhDidsqJNfRMKOmfHLY/ry9W0TeOHn4zhrVFfmri3ion9/zSvfbAx1eD/y1boitpRWcs7obqEOJawowYhI2IqLjWF83zT+7+xhfPnb4ziyXzq/nfYtT325PtSh/cC0+XkkJ8RxwuCOoQ4lrAQ8wZhZrJktMLP3Gjh/npktM7OlZvaiz/FaM1vovb0T6DhFJLy1jI/lyZ+O4ZShnbjrvWU8OHN1WOwpU767hv8t2cJpwzs365WT6xOMPpgpwHKgzd4nzKwfcCsw3jlXbGa+GydUOOdGBiE+EYkQCXGxPDR5FL+d9i3//HgVhWVVTDm+H2mtE0IW0/Sl+ZTvrlXzWD0CmmDMrBtwGnA3cGM9RX4B/Ms5VwzgnNsayHhEJPLFxcbwt58Mp03LOJ6encMr32zi1GGduOSwnozukRr0GfRvzPcsDZPZMzWo7xsJAt1Edj9wC9DQBtz9gf5mNtvMvjKzk33OJZpZlvf4WfU92cyu9JbJKiws9HPoIhKuYmKM288Ywowbj+LCcT2YuXwr5z46l1Mf/JL/fLmeop1VQYkjv7SSL9ds4+xR3SJmvk4wBSzBmNnpwFbnXPY+isUB/YBjgMnAv81szwpxPZxzmcCFwP1m1mfvJzvnnnDOZTrnMtPT0/1bAREJe307JHPHmUP46rYJ3H32UGJjYOp7yxj3fzP5xX+z+HhZQUD7ad5ckIdzcM6o5r2xWEMC2UQ2HjjTzE4FEoE2Zva8c+5inzK5wFfOuWpgvZmtxJNwvnHObQZwzq0zs1nAKCB6No0QEb9plRDHReN6ctG4nqzML2Pa/FzemJ/Hx8sKuGhcD6ZOHEqsn68wauscL83byNiMdmSktfLra0eLgF3BOOdudc51c85lABcAn+yVXADeAo4FMLM0PE1m68ws1cwSfI6PB5YFKlYRiR4DOiVz26mD+OrW47j66D688PVGrn1xvt+3Avh0xVY2bi/n0sMz/Pq60SToM/nNbCqQ5Zx7B5gOnGhmy4Ba4GbnXJGZHQ48bmZ1eJLgPc45JRgRabK42Bh+d8pA0lrH8+f3l1NcPo8nfppJm8QWfnn9Z+bk0DklkROHaO5LQywcxpH7Q2ZmpsvKygp1GCISht5akMdNry2if8dknrn8EDq0ObjlXFYXlHHCfZ9z80kD+NWxff0UZWiYWba3v9vvNJNfRKLeWaO68tRlh5BTtIszH57NkryD2575mTk5xMfFMHlsDz9FGJ2UYESkWTi6fzqvX304MQaTHpvLh0u2HNDrlFZU88b8PCaO6EK7VvF+jjK6KMGISLMxuEsb3rp2PAM7J3P18/P516dr9nsY82tZm6iorlXnfhMowYhIs9IhOZGXfnEoE0d24W/TV3Lnu8uanGRq6xzPzs1hbEY7hnZNCWygUUD7wYhIs5PYIpb7zx9JWusEnvpyPQktYvjdyQMbXWbmkxVb2bS9gltP0a6VTaEEIyLNkpnxh9MGUVVTy+OfrSMxLpYbTuhfb9mV+WW8mrWJafNzPUOTtSx/kyjBiEizZWZMPXMoVdV1PDBzNYktYrnqqN7klVSwZutOVhaU8b9vt7Aot5QWscbxgzryq2P7Eher3oWmUIIRkWYtJsa459zhVNXUce+HK3hw5moqfGb9D+iYzB9PH8xZI7vQPoTbAkQiJRgRafZiY4x/nDeCXmmtKKusoW+H1vTr2Jq+6a1J1VDkA6YEIyICtIiNabAPRg6MGhJFRCQglGBERCQglGBERCQglGBERCQglGBERCQglGBERCQglGBERCQglGBERCQgombLZDMrBDbsdTgF2HvrusaONXY/Ddh2gGHW9977U6Yp9QlWXRqLtbEy+1uXvR/vue97TJ9N02JtrIw+m9D+DdhXuUDUpZVzLr0JMe0/51zU3oAn9vdYY/eBLH/Gsz9lmlKfYNXlYOuzv3XZRx18j+mz0WcT1p9NU+riz88m0D9njd2ivYns3QM41pT7/oxnf8o0pT7BqktTX6ehMvtbl70fv9tAmQOlz2bfx/XZBO9vwL7KhVNdGhU1TWTBYmZZzrnMUMfhD9FUF4iu+kRTXSC66qO6NF20X8EEwhOhDsCPoqkuEF31iaa6QHTVR3VpIl3BiIhIQOgKRkREAkIJRkREAqJZJxgz+4+ZbTWzJQfw3DFm9q2ZrTGzB83MfM5dZ2YrzWypmf3Vv1E3GI/f62Jmd5hZnpkt9N5O9X/kDcYUkM/Ge/4mM3Nmlua/iPcZTyA+m7vMbLH3c/nIzLr4P/J64wlEXf5mZiu89XnTzNr6P/IGYwpEfSZ5f/frzCzggwEOpg4NvN6lZrbae7vU5/g+f6/qFcgx0OF+A44CRgNLDuC584DDAAP+B5ziPX4sMANI8D7uEMF1uQO4KVo+G++57sB0PJNy0yK1LkAbnzLXA49FcF1OBOK89+8F7o3knzNgEDAAmAVkhmsdvPFl7HWsHbDO+2+q937qvuq7r1uzvoJxzn0ObPc9ZmZ9zOxDM8s2sy/MbODezzOzznh+wec6z//8f4GzvKevAe5xzlV532NrYGvhEaC6hEwA63MfcAsQtNEtgaiLc26HT9FWBKk+AarLR865Gm/Rr4Buga3F9wJUn+XOuZXBiN/7fgdUhwacBHzsnNvunCsGPgZOPtC/E806wTTgCeA659wY4CbgkXrKdAVyfR7neo8B9AeONLOvzewzMzskoNHu28HWBeBab9PFf8wsNXChNslB1cfMzgTynHOLAh1oExz0Z2Nmd5vZJuAi4E8BjLUx/vg52+NneL4dh5I/6xMqTalDfboCm3we76nXAdU3rolv2iyYWWvgcOA1n+bFhPqK1nNszzfIODyXlocChwCvmllvb9YPGj/V5VHgLu/ju4B/4PkDEHQHWx8zSwJ+j6c5JqT89NngnPs98HszuxW4Frjdz6E2yl918b7W74Ea4AV/xrg//FmfUNlXHczscmCK91hf4AMz2w2sd86dTcP1OqD6KsH8UAxQ4pwb6XvQzGKBbO/Dd/D84fW9jO8GbPbezwXe8CaUeWZWh2dBucJABl6Pg66Lc67A53lPAu8FMuBGHGx9+gC9gEXeX7puwHwzG+ucyw9w7Hvzx8+ZrxeB9wlBgsFPdfF2Jp8OTAj2l7G9+PuzCYV66wDgnHsaeBrAzGYBlznncnyK5ALH+DzuhqevJpcDqW+gO6DC/QZk4NM5BswBJnnvGzCiged9g+cqZU+H16ne41cDU733++O53LQIrUtnnzI3AC9H8mezV5kcgtTJH6DPpp9PmeuA1yO4LicDy4D0YP58BfrnjCB18h9oHWi4k389nlaYVO/9dk2pb71xheIDDZcb8BKwBajGk6GvwPMt90NgkfeH/k8NPDcTWAKsBR7m+1UR4oHnvefmA8dFcF2eA74FFuP51tY5GHUJVH32KpND8EaRBeKzmeY9vhjPwoVdI7gua/B8EVvovQVlRFwA63O297WqgAJgejjWgXoSjPf4z7yfyRrg8sbqu6+blooREZGA0CgyEREJCCUYEREJCCUYEREJCCUYEREJCCUYEREJCCUYiWpmtjPI7/dvMxvsp9eqNc9qyUvM7N3GVhk2s7Zm9kt/vLeIP2iYskQ1M9vpnGvtx9eLc98vzBhQvrGb2bPAKufc3fsonwG855wbGoz4RBqjKxhpdsws3cymmdk33tt47/GxZjbHzBZ4/x3gPX6Zmb1mZu8CH5nZMWY2y8xeN88+Ji/s2RvDezzTe3+nd0HKRWb2lZl19B7v4338jZlNbeJV1ly+X7SztZnNNLP55tmfY6K3zD1AH+9Vz9+8ZW/2vs9iM7vTj/+NIo1SgpHm6AHgPufcIcC5wL+9x1cARznnRuFZnfj/fJ5zGHCpc+447+NRwK+BwUBvYHw979MK+Mo5NwL4HPiFz/s/4H3/Rtdz8q6DNQHPagoAlcDZzrnRePYf+oc3wf0OWOucG+mcu9nMTgT6AWOBkcAYMzuqsfcT8RctdinN0fHAYJ+VZtuYWTKQAjxrZv3wrBTbwuc5HzvnfPfcmOecywUws4V41oL6cq/32c33C4RmAyd47x/G93tpvAj8vYE4W/q8djaevTnAsxbU/3mTRR2eK5uO9Tz/RO9tgfdxazwJ5/MG3k/Er5RgpDmKAQ5zzlX4HjSzh4BPnXNne/szZvmc3rXXa1T53K+l/t+lavd9J2dDZfalwjk30sxS8CSqXwEP4tn/JR0Y45yrNrMcILGe5xvwF+fc4/v5viJ+oSYyaY4+wrN/CgBmtmdZ8xQgz3v/sgC+/1d4muYALmissHOuFM+2yDeZWQs8cW71JpdjgZ7eomVAss9TpwM/8+4Pgpl1NbMOfqqDSKOUYCTaJZlZrs/tRjx/rDO9Hd/L8GyxAPBX4C9mNhuIDWBMvwZuNLN5QGegtLEnOOcW4FkZ9wI8G3JlmlkWnquZFd4yRcBs77DmvznnPsLTBDfXzL4FXueHCUgkoDRMWSTIvLtrVjjnnJldAEx2zk1s7HkikUZ9MCLBNwZ42Dvyq4QQbUMtEmi6ghERkYBQH4yIiASEEoyIiASEEoyIiASEEoyIiASEEoyIiATE/wP5IV9vw0d0KwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trim the last 15 datapoints so that we have clearer view\n",
    "learn_lm.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to select a `learning_rate` where the slope is steep and not going upwards.<br>\n",
    "`lr=5e-3` seems to be a sensible choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.167812</td>\n",
       "      <td>4.067869</td>\n",
       "      <td>0.291104</td>\n",
       "      <td>21:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.200355</td>\n",
       "      <td>4.070581</td>\n",
       "      <td>0.290157</td>\n",
       "      <td>21:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.133083</td>\n",
       "      <td>4.029402</td>\n",
       "      <td>0.293869</td>\n",
       "      <td>21:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.056716</td>\n",
       "      <td>3.989157</td>\n",
       "      <td>0.298245</td>\n",
       "      <td>21:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.998321</td>\n",
       "      <td>3.979450</td>\n",
       "      <td>0.299676</td>\n",
       "      <td>21:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr=5e-3\n",
    "learn_lm.to_fp16()\n",
    "learn_lm.fit_one_cycle(5, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save('fit_freezed_5_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.load('fit_freezed_5_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.806393</td>\n",
       "      <td>3.795424</td>\n",
       "      <td>0.318980</td>\n",
       "      <td>23:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.786836</td>\n",
       "      <td>3.768348</td>\n",
       "      <td>0.324682</td>\n",
       "      <td>23:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.763445</td>\n",
       "      <td>3.743657</td>\n",
       "      <td>0.328573</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.717152</td>\n",
       "      <td>3.711501</td>\n",
       "      <td>0.332588</td>\n",
       "      <td>23:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.619674</td>\n",
       "      <td>3.682857</td>\n",
       "      <td>0.335828</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.578209</td>\n",
       "      <td>3.660896</td>\n",
       "      <td>0.338813</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.528988</td>\n",
       "      <td>3.642530</td>\n",
       "      <td>0.341307</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.461757</td>\n",
       "      <td>3.632708</td>\n",
       "      <td>0.342691</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.392899</td>\n",
       "      <td>3.631087</td>\n",
       "      <td>0.343060</td>\n",
       "      <td>24:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.364762</td>\n",
       "      <td>3.633080</td>\n",
       "      <td>0.342879</td>\n",
       "      <td>24:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now we see that the aacuracy is positively improving\n",
    "# we can unfreeze and train further\n",
    "learn_lm.unfreeze()\n",
    "learn_lm.fit_one_cycle(10,lr/5, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save('fine_tuned_lm')\n",
    "learn_lm.save_encoder('fine_tuned_lm_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"i liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i liked this movie because it was true to life , a true story about a lame social worker who gets his to check out his own fantasy club . He always thinks he is an artist , but he ca n't see how\n",
      "\n",
      "i liked this movie because of the heroic acts Richard Gere said to Richard Gere . i liked the way the film was supposed to be , and i was surprised how little was done in the moment . It\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie was really bad . The acting was poor , and the story had no excitement . And the \" plot \" , was non - existent , and had\n",
      "\n",
      "This movie was clearly done by people who did n't know what the TV series was . The whole story line was n't very interesting . The acting was quite\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"This movie was\"\n",
    "N_WORDS = 30\n",
    "N_SENTENCES = 2\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the language model is much more \"*IMDB like*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 48\n",
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs, num_workers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.save('imdb_textlist_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj some have praised _ xxunk _ as a xxmaj disney adventure for adults . i do n't think so -- at least not for thinking adults . \\n \\n  xxmaj this script suggests a beginning as a live - action movie , that struck someone as the type of crap you can not sell to adults anymore . xxmaj the \" crack staff \" of many older</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos * * * xxmaj warning - this review contains \" plot spoilers , \" though nothing could \" spoil \" this movie any more than it already is . xxmaj it really xxup is that bad . * * * \\n \\n  xxmaj before i begin , i 'd like to let everyone know that this definitely is one of those so - incredibly - bad - that</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj okay , so i 'm not a big video game buff , but was the game xxmaj house of the xxmaj dead really famous enough to make a movie from ? xxmaj sure , they went as far as to actually put in quick video game clips throughout the movie , as though justifying any particular scene of violence , but there are dozens and dozens of games</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj in xxup nyc , seaman xxmaj michael o'hara ( xxmaj orson xxmaj welles ) rescues xxmaj elsa xxmaj bannister ( xxmaj rita xxmaj hayworth ) from a mugging &amp; rape as she takes a horse &amp; carriage through xxmaj central xxmaj park -and lives to regret it . xxmaj xxunk - haired xxmaj hayworth 's a platinum blonde in this one ; as dazzling as fresh - fallen</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ultimate-model: IMDB review classifier\n",
    "Three simple steps to create our review classifier after fine tuning our language model with IMDb dataset:\n",
    "    1. Create a `text_classifier_learner` with `AWD_LSTM` as base archietecture(note that we can use any model here as base architecture, but it has to be the same with the one we just trained as language model. So if we want a transformer here, we would be training a transformer language model in the previous section)\n",
    "    2. Load the `fine-tuned-language-model-encoder`. We have save both the encoder as well as the entire model. We would only be needing the encoder's weights here as we will be replacing the head as a freshly initialize classifier and train it later.\n",
    "    3. Freeze the body(base architecture) of our model, and train just the head first. We can make use of our usual trategy be looking for the optimal learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.3)\n",
    "learn_clas.load_encoder('fine_tuned_lm_enc')\n",
    "learn_clas.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn_clas.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will be turning our model to mixed-precision in order to speed up the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.to_fp16();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.242503</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>0.921240</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.245878</td>\n",
       "      <td>0.232431</td>\n",
       "      <td>0.908080</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.219563</td>\n",
       "      <td>0.914240</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.242020</td>\n",
       "      <td>0.179243</td>\n",
       "      <td>0.933080</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230897</td>\n",
       "      <td>0.175639</td>\n",
       "      <td>0.935120</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.225465</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.934600</td>\n",
       "      <td>02:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.224750</td>\n",
       "      <td>0.173133</td>\n",
       "      <td>0.935280</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.203338</td>\n",
       "      <td>0.175705</td>\n",
       "      <td>0.934680</td>\n",
       "      <td>02:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.194384</td>\n",
       "      <td>0.172137</td>\n",
       "      <td>0.936440</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.212245</td>\n",
       "      <td>0.184981</td>\n",
       "      <td>0.935640</td>\n",
       "      <td>02:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.fit_one_cycle(10, 2e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_freezed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradual unfreezing during fine-tuning our classifier\n",
    "Fine-tuning the target classifier is the most critical part of the *transfer learning method*. Overly aggressive fine-tuning will cause catastrophic forgetting, eliminating the benefit of the information captured through language modeling; too cautious fine-tuning will lead to slow convergence (and resultant overfiting). Besides discriminative fine-tuning and triangular learning rates, **gradual unfreezing** is proposed.\n",
    "\n",
    "Jeremy et al. found that for RNN-base NLP models, by gradually unfreeze the layers from head to bottom we minimize the forgetting incurred for each *transfer learning* thus maximize our effort done in the previous training section.\n",
    "\n",
    "We first unfreeze the **last layer** and fine-tune all un-frozen layers for one epoch.\n",
    "\n",
    "Then unfreeze the **next lower frozen layer** and repeat.\n",
    "\n",
    "Until all unfrozen layers converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.222187</td>\n",
       "      <td>0.180545</td>\n",
       "      <td>0.931840</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.199225</td>\n",
       "      <td>0.155029</td>\n",
       "      <td>0.943760</td>\n",
       "      <td>02:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.155391</td>\n",
       "      <td>0.151604</td>\n",
       "      <td>0.945680</td>\n",
       "      <td>02:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093648</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.943680</td>\n",
       "      <td>02:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.058335</td>\n",
       "      <td>0.191606</td>\n",
       "      <td>0.941960</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(5, slice(1e-2/(2.6**4),1e-2), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreed_second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.064002</td>\n",
       "      <td>0.204184</td>\n",
       "      <td>0.940280</td>\n",
       "      <td>03:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.090188</td>\n",
       "      <td>0.196067</td>\n",
       "      <td>0.936440</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051633</td>\n",
       "      <td>0.197808</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>03:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025068</td>\n",
       "      <td>0.227497</td>\n",
       "      <td>0.944320</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011097</td>\n",
       "      <td>0.242228</td>\n",
       "      <td>0.944400</td>\n",
       "      <td>03:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-3)\n",
    "learn_clas.fit_one_cycle(5, slice(5e-3/(2.6**4), 5e-3), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreezed_third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.load('learn_clas_unfreezed_third');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.236845</td>\n",
       "      <td>0.943680</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.244636</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.256718</td>\n",
       "      <td>0.944560</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.262101</td>\n",
       "      <td>0.944880</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>0.271987</td>\n",
       "      <td>0.943320</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.276141</td>\n",
       "      <td>0.943960</td>\n",
       "      <td>04:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.276535</td>\n",
       "      <td>0.944960</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.292337</td>\n",
       "      <td>0.945400</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.945200</td>\n",
       "      <td>04:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.294201</td>\n",
       "      <td>0.944960</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.305880</td>\n",
       "      <td>0.946320</td>\n",
       "      <td>04:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.310033</td>\n",
       "      <td>0.946040</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.298653</td>\n",
       "      <td>0.945640</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006778</td>\n",
       "      <td>0.302350</td>\n",
       "      <td>0.945440</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.306093</td>\n",
       "      <td>0.946720</td>\n",
       "      <td>03:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.unfreeze()\n",
    "learn_clas.fit_one_cycle(15, slice(4e-4/(2.6**4),5e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreezed_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state-of-the-art result for IMDB sentimant classification result in 2017 is **94.1%**\n",
    "What we can do even better, is to build a **reversed model** as well and training a meta-learner on top of that.\n",
    "For this technique, we will be experimenting with more detail in my [sentiment analysis with non-English language]() repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
