{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "# our models of choice\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.55\n",
      "transformers version : 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers model Zoo\n",
    "Create a dictionary of parameters required for creating different model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make model selection here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 16\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-uncased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "#model_type = 'xlm'\n",
    "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "\n",
    "#model_type = 'xlnet'\n",
    "#pretrained_model_name = 'xlnet-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the same randomization seed so as to compare different models more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "The important thing here is that `FastAI` uses **processors** to perform repeatetive tasks when creating `DataBunch`. A set of default **processors** are performed for fastai.textlearners. For example:\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAI use various processors to perform repeatative tasks in data pipeline\n",
    "\n",
    "def _get_processor(tokenizer:Tokenizer=None, vocab:Vocab=None, chunksize:int=10000, max_vocab:int=60000,\n",
    "                   min_freq:int=2, mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False):\n",
    "    return [TokenizeProcessor(tokenizer=tokenizer, chunksize=chunksize, \n",
    "                              mark_fields=mark_fields, include_bos=include_bos, include_eos=include_eos),\n",
    "            NumericalizeProcessor(vocab=vocab, max_vocab=max_vocab, min_freq=min_freq)]\n",
    "\n",
    "class NumericalizeProcessor(PreProcessor):\n",
    "    \"`PreProcessor` that numericalizes the tokens in `ds`.\"\n",
    "    def __init__(self, ds:ItemList=None, vocab:Vocab=None, max_vocab:int=60000, min_freq:int=3):\n",
    "        vocab = ifnone(vocab, ds.vocab if ds is not None else None)\n",
    "        self.vocab,self.max_vocab,self.min_freq = vocab,max_vocab,min_freq\n",
    "\n",
    "    def process_one(self,item): return np.array(self.vocab.numericalize(item), dtype=np.int64)\n",
    "    def process(self, ds):\n",
    "        if self.vocab is None: self.vocab = Vocab.create(ds.items, self.max_vocab, self.min_freq)\n",
    "        ds.vocab = self.vocab\n",
    "        super().process(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to overwrite the \"tokenizer\" and \"numericalizer\" in order to tailor the databunch creating process to the `Transformers`\n",
    "Later when creating `DataBunch`, we are going to pass in our customized processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "Step 1: create a new tokenizer that inherit from `fastai`'s `BaseTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "        return [CLS] + tokens + [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Get the 'pre-trained tokenizer' from `transformer` library.(this is used for initialization of the class we created above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2262ef28ef74d4c891ff87ce174eea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=898823, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebc629ce6d647d49c59226cf9a1ada4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=456318, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create the actual **tokenizer** for our transformer of choice and put a `FastAI` wrapper on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.transform.Tokenizer"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, be carefull about 3 things :\n",
    "\n",
    "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
    "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
    "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with add_prefix_space set to True.\n",
    "\n",
    "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the [HuggingFace documentation](https://huggingface.co/transformers/) in each model section.<br>\n",
    "`bert:       [CLS] + tokens + [SEP] + padding`<br>\n",
    "`roberta:    [CLS] + prefix_space + tokens + [SEP] + padding`<br>\n",
    "`distilbert: [CLS] + tokens + [SEP] + padding`<br>\n",
    "`xlm:        [CLS] + tokens + [SEP] + padding`<br>\n",
    "`xlnet:      padding + [CLS] + tokens + [SEP]`\n",
    "\n",
    "It is worth noting that we don't add padding in this part of the implementation.  As we will see later, fastai manage it automatically during the creation of the `DataBunch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalizer\n",
    "In `fastai` library, `NumericalizeProcessor` object takes as `bocab` argument a `Vocab` object. Here we will create a new class `TransformerVocab` that inherits from `Vocab` and overwrite `numericalize` and `textify` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize numericalize processor\n",
    "Notice taht we need to pass the `include_bs=False` and `include_eos=False` options. This is because `fastiai` adds its own special tokens by default which interferes with the `[CLS]` and `[SEP]` tokens that are required for RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.NumericalizeProcessor"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumericalizeProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use RoBERTa tokenizer to initialize the `TransformersVocab\n",
    "transformer_vocab = TransformersVocab(tokenizer=transformer_tokenizer)\n",
    "\n",
    "# create a customized numericalizor using vocab just created\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put together our customized processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.TokenizeProcessor"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenizeProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function over the tokenizer we created above\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally put the two processors in a list for later use\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataBunch\n",
    "For the DataBunch creation, you have to pay attention to set the processor argument to our new custom processor `transformer_processor` and manage correctly the padding.\n",
    "\n",
    "As mentioned in the [HuggingFace documentation](https://huggingface.co/transformers/), BERT, RoBERTa, XLM and DistilBERT are models with absolute position embeddings, so it's usually advised to pad the inputs on the right rather than the left. Regarding XLNET, it is a model with relative position embeddings, therefore, you can either pad the inputs on the right or on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are using Google XLNet\n",
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the full IMDB dataset and inspect the files under that path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/projectx/.fastai/data/imdb')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/test'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/imdb_textlist_classifier'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/lm_databunch'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/pos'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/neg')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for LM training\n",
    "The reviews are in a training and test folder. In addition, we have a 'unsup' folder that contains many reviews are \n",
    "are **not labelled**.<br>\n",
    "In the second training phase of ULMFiT, as mentioned in the [README](https://github.com/Sylar257/Sentiment-Analysis/blob/master/README.md)\n",
    ", we will be fine-tuning the language model to the domain-specific corpus.<br>\n",
    "Thus, training could take advantage of using 'train', 'test', and 'unsup' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataBunch for language model\n",
    "What does that mean?<br>\n",
    "Basically we are creating a databunch for our learner later in a way that we ignore the true label('negataive' or  'positive'). Hence, the task we constructed is as simple as to just predict the **next word** without worrying about what the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# we can play around with the batch_size as long as the GPU can take it\n",
    "bs = 48\n",
    "data_lm = (TextList.from_folder(path, processor=transformer_processor)                         # specify the path\n",
    "           .filter_by_folder(include=['train','test','unsup'])# exclude other folders\n",
    "           .split_by_rand_pct(0.1, seed=seed)                 # randomly split and keep 10% for validation set\n",
    "           .label_for_lm()                                    # label as to \"predict the next word token\"\n",
    "           .databunch(bs=bs))                                 # convert to databunch for the learner later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.train_ds), len(data_lm.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/ 55 21 _ 8 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 8 180 _ 9 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 59 17 _ 8 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai /</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/ test / pos / 26 44 _ 10 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 55 15 _ 10 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 782 _ 9 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>im db / test / pos / 14 18 _ 10 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 59 19 _ 8 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 92 11 _ 9 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home /</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>_ 9 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 11 103 _ 10 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 8 644 _ 10 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>im db / test / pos / 9 808 _ 10 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 12 395 _ 10 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home / project x /. fast ai / data / im db / test / pos / 14 07 _ 7 . txt &lt;/s&gt; &lt;s&gt; Ġ/ home /</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a peek at a small sample of data\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>for romantic comedies ( i do n't know why ) . xxmaj the trailers i saw were not appealing , the cast did not look that interesting and i had no idea what the plot would be about . xxmaj in the end i found it to be an interesting meditation on relationships and family . i thoroughly enjoyed myself and must admit that i thought that this film was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>use of the word . xxmaj yes , it 's gritty , sexy , down home truth , bizarre and in - your - face real . xxmaj is n't that the best reason to see a movie ? xxmaj those that get my meaning wo n't stay away from seeing this another week . xxbos xxmaj this brings back so many childhood memories . ( i 'm not old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>xxmaj now i 'm convinced more than ever , that my appraisal was correct after seeing a master film maker like xxmaj jean xxmaj renoir 's version of the same story . xxmaj he succeeded in getting great performances out of his entire cast , and the great xxmaj french actor , xxmaj jean xxmaj gabin was in rare form . xxmaj the dance sequence near the end was one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>it 's difficult to talk to her ? \\n \\n  xxmaj this film is not as fascinating as xxmaj cassavetes 's xxmaj faces or xxmaj opening xxmaj night , but it has that riveting quality that xxmaj cassavetes always fought so hard to render , which is an unbridled depiction of people underneath the ego that hides behind itself in nearly all other films . xxmaj gena xxmaj rowlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>'s xxmaj westerns are my favorites and this slides easily to a satisfaction . a xxmaj western of this kind is in the pages of the past and perhaps never to be made much again . xxmaj one to enjoy . xxmaj gave it a 7 rating . xxmaj likely 6.8 worthy but films like these become more precious over time . \\n \\n  xxmaj for film - noir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is a comparison with databunch processed by FastAI defaul processors\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save our databunch so that we don't have to re-run this the next time\n",
    "data_lm.save('lm_databunch_RoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/lm_databunch_RoBERTa'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/test'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/imdb_textlist_classifier'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/lm_databunch'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the databunch is saved under 'path' rather than the current directory\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the databunch we created ealier\n",
    "bs = 48\n",
    "data_lm = load_data(path, 'lm_databunch_RoBERTa', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : <s>\n",
      "[SEP] token : </s>\n",
      "[PAD] token : <pad>\n"
     ]
    }
   ],
   "source": [
    "# a sanity check for <s>; </s>; <pad>\n",
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 0\n",
      "[SEP] id : 2\n",
      "[PAD] id : 1\n",
      "Batch shape :  torch.Size([48, 70])\n",
      "tensor([[23687,    73,   757,  ...,     2,     0,  1589],\n",
      "        [16963,  1439,    73,  ...,   466,     4, 46795],\n",
      "        [28258,  1178, 11665,  ...,  2983,  1215,   406],\n",
      "        ...,\n",
      "        [   73, 28258,  1178,  ...,  1215,   288,     4],\n",
      "        [ 8361,    73, 28258,  ..., 26300,  1215,   288],\n",
      "        [11665, 16963,  1439,  ..., 46795,     2,     0]])\n"
     ]
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = data_lm.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize model\n",
    "As mentioned [here](https://github.com/huggingface/transformers#models-always-output-tuples), every model's forward method always outputs a tuple with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits.  One way to access them is to create a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                attention_mask = attention_mask)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pretrained weights for RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 50265,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the configuration of language model\n",
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = transformer_tokenizer.vocab_size\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "CustomTransformerModel(\n  (transformer): RobertaForSequenceClassification(\n    (roberta): RobertaModel(\n      (embeddings): RobertaEmbeddings(\n        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n        (position_embeddings): Embedding(514, 768, padding_idx=1)\n        (token_type_embeddings): Embedding(1, 768)\n        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (1): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (2): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (3): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (4): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (5): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (6): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (7): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (8): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (9): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (10): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (11): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n    (classifier): RobertaClassificationHead(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (dropout): Dropout(p=0.1)\n      (out_proj): Linear(in_features=768, out_features=50265, bias=True)\n    )\n  )\n)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-3129d72a44e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m learn_lm = language_model_learner(data_lm, \n\u001b[1;32m      2\u001b[0m                    \u001b[0mcustom_transformer_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                    opt_func = CustomAdamW)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mShowGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_lm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mlanguage_model_learner\u001b[0;34m(data, arch, config, drop_mult, pretrained, pretrained_fnames, **learn_kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            pretrained_fnames:OptStrTuple=None, **learn_kwargs) -> 'LanguageLearner':\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m\"Create a `Learner` with a language model from `data` and `arch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_mult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_model_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_lm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlearn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mget_language_model\u001b[0;34m(arch, vocab_sz, config, drop_mult)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_sz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"Create a language model from `arch` and its `config`, maybe `pretrained`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_model_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config_lm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: CustomTransformerModel(\n  (transformer): RobertaForSequenceClassification(\n    (roberta): RobertaModel(\n      (embeddings): RobertaEmbeddings(\n        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n        (position_embeddings): Embedding(514, 768, padding_idx=1)\n        (token_type_embeddings): Embedding(1, 768)\n        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (1): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (2): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (3): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (4): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (5): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (6): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (7): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (8): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (9): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (10): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (11): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n    (classifier): RobertaClassificationHead(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (dropout): Dropout(p=0.1)\n      (out_proj): Linear(in_features=768, out_features=50265, bias=True)\n    )\n  )\n)"
     ]
    }
   ],
   "source": [
    "learn_lm = language_model_learner(data_lm, \n",
    "                   custom_transformer_model, \n",
    "                   opt_func = CustomAdamW)\n",
    "learn_lm.callbacks.append(ShowGraph(learn_lm))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel(\n",
       "  (transformer): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "      (out_proj): Linear(in_features=768, out_features=50265, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (48) to match target batch_size (3360).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-7763fef4d0dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input, target, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatify\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_2d\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCrossEntropyFlat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 942\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1867\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1869\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (48) to match target batch_size (3360)."
     ]
    }
   ],
   "source": [
    "learn_lm.lr_find()\n",
    "learn_lm.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will be creating our leaner with the base architecture being `AWD_LSTM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Padding_idx must be within num_embeddings",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-e950d9b385f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# the drop_mult decide the percentage of dropout to use in relation to the combination used in the original paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn_lm_AWD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_model_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mlanguage_model_learner\u001b[0;34m(data, arch, config, drop_mult, pretrained, pretrained_fnames, **learn_kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            pretrained_fnames:OptStrTuple=None, **learn_kwargs) -> 'LanguageLearner':\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m\"Create a `Learner` with a language model from `data` and `arch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_mult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_model_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_lm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlearn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mget_language_model\u001b[0;34m(arch, vocab_sz, config, drop_mult)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mtie_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'tie_weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out_bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'init'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtie_weights\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hid_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtie_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mold_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/text/models/awd_lstm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token, hidden_p, input_p, embed_p, weight_p, qrnn, bidir)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_hid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbidir\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddingDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqrnn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Padding_idx must be within num_embeddings"
     ]
    }
   ],
   "source": [
    "# the drop_mult decide the percentage of dropout to use in relation to the combination used in the original paper\n",
    "learn_lm_AWD = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "As we can see below, when we create `TextDataBunch` a  `vocab` property is created simultaneously. <br>\n",
    "It's worth pointing out that, for `index-to-strings` and `strings-to-index` we have a different length. This is primarily because that there are some words that appear infrequently so that it's not effcient for them to occupy one token. What we do is to map all of these low frequency words to `xxunk`. We can ditermine the `min_freq` in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = data_lm.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35055"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[\"stingray\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[\"happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.itos[vocab.stoi['mamamia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn_lm.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(60000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ourmodel has two parts, the AWD_LSTM base architecture and the linear classifier\n",
    "learn_lm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on `drop_mult`\n",
    "From the original [AWD_LSTM paper](https://arxiv.org/pdf/1708.02182.pdf) the authors applied several effective techniques.<br>\n",
    "\n",
    "**DropConnect** was implemented in the architecture in that weight matrices are *dropped* before the *forward* and *backward* pass.<br>\n",
    "\n",
    "**Variational dropout**. In standard dropout, a new binary dropout mask is sampled each and every time the dropout function is called. **Variational dropout** only samples a *dropout mask* upon the first call and then will repeatedly use that *locked dropout* mask for all repeated connections within the forward and backward pass.<br>\n",
    "\n",
    "The values used for *dropout on the word vectors*, the *output between LSTM layers*, the *output of the final LSTM layer*, and *embedding dropout* were (0.4, 0.3, 0.4, 0.1), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Encoder is the first layer of the AWD_LSTM, which is also known as the `embedding layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 400])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = learn_lm.model[0].encoder\n",
    "enc.weight.size()  # 400 is the embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall that 60000 is the vocab size of our language model vocabulary\n",
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before training\n",
    "Let's try to use this model(only pre-trained with wiki-text) to generate fake movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = 'The color of the sky is'\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the sky is often changed from black to blue , to give it a more light color . The color is derived from the colours of one of the sky planets and the blue sky . The bird 's colour is\n",
      "\n",
      "The color of the sky is a reference to the thin red hair of the Earth . The physical presence of the moon in the sky and the dark sky in the dark , and the so - called Earth - like sky\n"
     ]
    }
   ],
   "source": [
    "# Note that the 'temperature' denote the randomness we adopt when pick next words\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the sky is a matter of controversy , as the Sun is not a white sky , but a white sky . The Sun is a dark , dark , dark , dark , dark , dark , dark ,\n",
      "\n",
      "The color of the sky is a matter of debate , and the International Union of Red and White Stars ( NAACP ) has been the most popular group of the American public . The American\n",
      "\n",
      "The color of the sky is a matter of controversy , as the Sun has been described as a \" dark , dark , dark , dark , dark , dark , dark , dark , dark , dark , dark , dark , dark\n"
     ]
    }
   ],
   "source": [
    "# If 'temperature'  set to super low, there will be almost no randomness\n",
    "N_SENTENCES = 3\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.05) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hate this movie so much it does not last for a single , less weekly , or just a few more pages of a book , so it can be seen as Lily Allen 's second novel The Spirit of\n",
      "\n",
      "I hate this movie so much that i think i would be thinking about it . The greatest reason why i wanted to make a movie about a movie was that you would not let it go , because it was not a chance to\n",
      "\n",
      "I hate this movie so much that i can ' t do that . It could make you want to see what is right . But i don ' t hope to see what the right thing can do , and as many as\n"
     ]
    }
   ],
   "source": [
    "# Change TEXT\n",
    "TEXT = 'I hate this movie so much'\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc(LanguageLearner.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning a language model\n",
    "We can use the `data_lm` object we created earlier to fine-tune a pretrained language model. \n",
    "Here we will be using a pre-trained `AWD-LSTM` architecture theat is available in FastAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn_lm.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot function attached to lr_finder\n",
    "# Note that we get a smoothened version where `skip_start` and `skip_end` decide howmuch to trim-off from start or end\n",
    "\n",
    "def plot(self, skip_start:int=10, skip_end:int=5, suggestion:bool=False, return_fig:bool=None,\n",
    "             **kwargs)->Optional[plt.Figure]:\n",
    "        \"Plot learning rate and losses, trimmed between `skip_start` and `skip_end`. Optionally plot and return min gradient\"\n",
    "        lrs = self._split_list(self.lrs, skip_start, skip_end)\n",
    "        losses = self._split_list(self.losses, skip_start, skip_end)\n",
    "        losses = [x.item() for x in losses]\n",
    "        if 'k' in kwargs: losses = self.smoothen_by_spline(lrs, losses, **kwargs)\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.plot(lrs, losses)\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_xlabel(\"Learning Rate\")\n",
    "        ax.set_xscale('log')\n",
    "        ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
    "        if suggestion:\n",
    "            try: mg = (np.gradient(np.array(losses))).argmin()\n",
    "            except:\n",
    "                print(\"Failed to compute the gradients, there might not be enough points.\")\n",
    "                return\n",
    "            print(f\"Min numerical gradient: {lrs[mg]:.2E}\")\n",
    "            ax.plot(lrs[mg],losses[mg],markersize=10,marker='o',color='red')\n",
    "            self.min_grad_lr = lrs[mg]\n",
    "            ml = np.argmin(losses)\n",
    "            print(f\"Min loss divided by 10: {lrs[ml]/10:.2E}\")\n",
    "        if ifnone(return_fig, defaults.return_fig): return fig\n",
    "        if not IN_NOTEBOOK: plot_sixel(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trim the last 15 datapoints so that we have clearer view\n",
    "learn_lm.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to select a `learning_rate` where the slope is steep and not going upwards.<br>\n",
    "`lr=5e-3` seems to be a sensible choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.167812</td>\n",
       "      <td>4.067869</td>\n",
       "      <td>0.291104</td>\n",
       "      <td>21:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.200355</td>\n",
       "      <td>4.070581</td>\n",
       "      <td>0.290157</td>\n",
       "      <td>21:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.133083</td>\n",
       "      <td>4.029402</td>\n",
       "      <td>0.293869</td>\n",
       "      <td>21:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.056716</td>\n",
       "      <td>3.989157</td>\n",
       "      <td>0.298245</td>\n",
       "      <td>21:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.998321</td>\n",
       "      <td>3.979450</td>\n",
       "      <td>0.299676</td>\n",
       "      <td>21:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr=5e-3\n",
    "learn_lm.to_fp16()\n",
    "learn_lm.fit_one_cycle(5, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save('fit_freezed_5_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.load('fit_freezed_5_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.806393</td>\n",
       "      <td>3.795424</td>\n",
       "      <td>0.318980</td>\n",
       "      <td>23:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.786836</td>\n",
       "      <td>3.768348</td>\n",
       "      <td>0.324682</td>\n",
       "      <td>23:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.763445</td>\n",
       "      <td>3.743657</td>\n",
       "      <td>0.328573</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.717152</td>\n",
       "      <td>3.711501</td>\n",
       "      <td>0.332588</td>\n",
       "      <td>23:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.619674</td>\n",
       "      <td>3.682857</td>\n",
       "      <td>0.335828</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.578209</td>\n",
       "      <td>3.660896</td>\n",
       "      <td>0.338813</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.528988</td>\n",
       "      <td>3.642530</td>\n",
       "      <td>0.341307</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.461757</td>\n",
       "      <td>3.632708</td>\n",
       "      <td>0.342691</td>\n",
       "      <td>23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.392899</td>\n",
       "      <td>3.631087</td>\n",
       "      <td>0.343060</td>\n",
       "      <td>24:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.364762</td>\n",
       "      <td>3.633080</td>\n",
       "      <td>0.342879</td>\n",
       "      <td>24:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now we see that the aacuracy is positively improving\n",
    "# we can unfreeze and train further\n",
    "learn_lm.unfreeze()\n",
    "learn_lm.fit_one_cycle(10,lr/5, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save('fine_tuned_lm')\n",
    "learn_lm.save_encoder('fine_tuned_lm_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"i liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i liked this movie because it was true to life , a true story about a lame social worker who gets his to check out his own fantasy club . He always thinks he is an artist , but he ca n't see how\n",
      "\n",
      "i liked this movie because of the heroic acts Richard Gere said to Richard Gere . i liked the way the film was supposed to be , and i was surprised how little was done in the moment . It\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie was really bad . The acting was poor , and the story had no excitement . And the \" plot \" , was non - existent , and had\n",
      "\n",
      "This movie was clearly done by people who did n't know what the TV series was . The whole story line was n't very interesting . The acting was quite\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"This movie was\"\n",
    "N_WORDS = 30\n",
    "N_SENTENCES = 2\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the language model is much more \"*IMDB like*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 48\n",
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs, num_workers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.save('imdb_textlist_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj some have praised _ xxunk _ as a xxmaj disney adventure for adults . i do n't think so -- at least not for thinking adults . \\n \\n  xxmaj this script suggests a beginning as a live - action movie , that struck someone as the type of crap you can not sell to adults anymore . xxmaj the \" crack staff \" of many older</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos * * * xxmaj warning - this review contains \" plot spoilers , \" though nothing could \" spoil \" this movie any more than it already is . xxmaj it really xxup is that bad . * * * \\n \\n  xxmaj before i begin , i 'd like to let everyone know that this definitely is one of those so - incredibly - bad - that</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj okay , so i 'm not a big video game buff , but was the game xxmaj house of the xxmaj dead really famous enough to make a movie from ? xxmaj sure , they went as far as to actually put in quick video game clips throughout the movie , as though justifying any particular scene of violence , but there are dozens and dozens of games</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj in xxup nyc , seaman xxmaj michael o'hara ( xxmaj orson xxmaj welles ) rescues xxmaj elsa xxmaj bannister ( xxmaj rita xxmaj hayworth ) from a mugging &amp; rape as she takes a horse &amp; carriage through xxmaj central xxmaj park -and lives to regret it . xxmaj xxunk - haired xxmaj hayworth 's a platinum blonde in this one ; as dazzling as fresh - fallen</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ultimate-model: IMDB review classifier\n",
    "Three simple steps to create our review classifier after fine tuning our language model with IMDb dataset:\n",
    "    1. Create a `text_classifier_learner` with `AWD_LSTM` as base archietecture(note that we can use any model here as base architecture, but it has to be the same with the one we just trained as language model. So if we want a transformer here, we would be training a transformer language model in the previous section)\n",
    "    2. Load the `fine-tuned-language-model-encoder`. We have save both the encoder as well as the entire model. We would only be needing the encoder's weights here as we will be replacing the head as a freshly initialize classifier and train it later.\n",
    "    3. Freeze the body(base architecture) of our model, and train just the head first. We can make use of our usual trategy be looking for the optimal learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.3)\n",
    "learn_clas.load_encoder('fine_tuned_lm_enc')\n",
    "learn_clas.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn_clas.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will be turning our model to mixed-precision in order to speed up the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.to_fp16();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.242503</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>0.921240</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.245878</td>\n",
       "      <td>0.232431</td>\n",
       "      <td>0.908080</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.219563</td>\n",
       "      <td>0.914240</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.242020</td>\n",
       "      <td>0.179243</td>\n",
       "      <td>0.933080</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230897</td>\n",
       "      <td>0.175639</td>\n",
       "      <td>0.935120</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.225465</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.934600</td>\n",
       "      <td>02:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.224750</td>\n",
       "      <td>0.173133</td>\n",
       "      <td>0.935280</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.203338</td>\n",
       "      <td>0.175705</td>\n",
       "      <td>0.934680</td>\n",
       "      <td>02:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.194384</td>\n",
       "      <td>0.172137</td>\n",
       "      <td>0.936440</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.212245</td>\n",
       "      <td>0.184981</td>\n",
       "      <td>0.935640</td>\n",
       "      <td>02:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.fit_one_cycle(10, 2e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_freezed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradual unfreezing during fine-tuning our classifier\n",
    "Fine-tuning the target classifier is the most critical part of the *transfer learning method*. Overly aggressive fine-tuning will cause catastrophic forgetting, eliminating the benefit of the information captured through language modeling; too cautious fine-tuning will lead to slow convergence (and resultant overfiting). Besides discriminative fine-tuning and triangular learning rates, **gradual unfreezing** is proposed.\n",
    "\n",
    "Jeremy et al. found that for RNN-base NLP models, by gradually unfreeze the layers from head to bottom we minimize the forgetting incurred for each *transfer learning* thus maximize our effort done in the previous training section.\n",
    "\n",
    "We first unfreeze the **last layer** and fine-tune all un-frozen layers for one epoch.\n",
    "\n",
    "Then unfreeze the **next lower frozen layer** and repeat.\n",
    "\n",
    "Until all unfrozen layers converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.222187</td>\n",
       "      <td>0.180545</td>\n",
       "      <td>0.931840</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.199225</td>\n",
       "      <td>0.155029</td>\n",
       "      <td>0.943760</td>\n",
       "      <td>02:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.155391</td>\n",
       "      <td>0.151604</td>\n",
       "      <td>0.945680</td>\n",
       "      <td>02:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093648</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.943680</td>\n",
       "      <td>02:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.058335</td>\n",
       "      <td>0.191606</td>\n",
       "      <td>0.941960</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(5, slice(1e-2/(2.6**4),1e-2), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreed_second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.064002</td>\n",
       "      <td>0.204184</td>\n",
       "      <td>0.940280</td>\n",
       "      <td>03:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.090188</td>\n",
       "      <td>0.196067</td>\n",
       "      <td>0.936440</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051633</td>\n",
       "      <td>0.197808</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>03:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025068</td>\n",
       "      <td>0.227497</td>\n",
       "      <td>0.944320</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011097</td>\n",
       "      <td>0.242228</td>\n",
       "      <td>0.944400</td>\n",
       "      <td>03:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.freeze_to(-3)\n",
    "learn_clas.fit_one_cycle(5, slice(5e-3/(2.6**4), 5e-3), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreezed_third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.load('learn_clas_unfreezed_third');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.236845</td>\n",
       "      <td>0.943680</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.244636</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.256718</td>\n",
       "      <td>0.944560</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.262101</td>\n",
       "      <td>0.944880</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>0.271987</td>\n",
       "      <td>0.943320</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.276141</td>\n",
       "      <td>0.943960</td>\n",
       "      <td>04:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.276535</td>\n",
       "      <td>0.944960</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.292337</td>\n",
       "      <td>0.945400</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.945200</td>\n",
       "      <td>04:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.294201</td>\n",
       "      <td>0.944960</td>\n",
       "      <td>04:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.305880</td>\n",
       "      <td>0.946320</td>\n",
       "      <td>04:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.310033</td>\n",
       "      <td>0.946040</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.298653</td>\n",
       "      <td>0.945640</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006778</td>\n",
       "      <td>0.302350</td>\n",
       "      <td>0.945440</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.306093</td>\n",
       "      <td>0.946720</td>\n",
       "      <td>03:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_clas.unfreeze()\n",
    "learn_clas.fit_one_cycle(15, slice(4e-4/(2.6**4),5e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreezed_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state-of-the-art result for IMDB sentimant classification result in 2017 is **94.1%**\n",
    "What we can do even better, is to build a **reversed model** as well and training a meta-learner on top of that.\n",
    "For this technique, we will be experimenting with more detail in my [sentiment analysis with non-English language]() repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
