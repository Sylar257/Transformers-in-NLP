{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "# our models of choice\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.59\n",
      "transformers version : 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers model Zoo\n",
    "Create a dictionary of parameters required for creating different model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make model selection here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 16\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-uncased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "#model_type = 'xlm'\n",
    "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "\n",
    "#model_type = 'xlnet'\n",
    "#pretrained_model_name = 'xlnet-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the same randomization seed so as to compare different models more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "The important thing here is that `FastAI` uses **processors** to perform repeatetive tasks when creating `DataBunch`. A set of default **processors** are performed for fastai.textlearners. For example:\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAI use various processors to perform repeatative tasks in data pipeline\n",
    "\n",
    "def _get_processor(tokenizer:Tokenizer=None, vocab:Vocab=None, chunksize:int=10000, max_vocab:int=60000,\n",
    "                   min_freq:int=2, mark_fields:bool=False, include_bos:bool=True, include_eos:bool=False):\n",
    "    return [TokenizeProcessor(tokenizer=tokenizer, chunksize=chunksize, \n",
    "                              mark_fields=mark_fields, include_bos=include_bos, include_eos=include_eos),\n",
    "            NumericalizeProcessor(vocab=vocab, max_vocab=max_vocab, min_freq=min_freq)]\n",
    "\n",
    "class NumericalizeProcessor(PreProcessor):\n",
    "    \"`PreProcessor` that numericalizes the tokens in `ds`.\"\n",
    "    def __init__(self, ds:ItemList=None, vocab:Vocab=None, max_vocab:int=60000, min_freq:int=3):\n",
    "        vocab = ifnone(vocab, ds.vocab if ds is not None else None)\n",
    "        self.vocab,self.max_vocab,self.min_freq = vocab,max_vocab,min_freq\n",
    "\n",
    "    def process_one(self,item): return np.array(self.vocab.numericalize(item), dtype=np.int64)\n",
    "    def process(self, ds):\n",
    "        if self.vocab is None: self.vocab = Vocab.create(ds.items, self.max_vocab, self.min_freq)\n",
    "        ds.vocab = self.vocab\n",
    "        super().process(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to overwrite the \"tokenizer\" and \"numericalizer\" in order to tailor the databunch creating process to the `Transformers`\n",
    "Later when creating `DataBunch`, we are going to pass in our customized processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "Step 1: create a new tokenizer that inherit from `fastai`'s `BaseTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "        return [CLS] + tokens + [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Get the 'pre-trained tokenizer' from `transformer` library.(this is used for initialization of the class we created above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create the actual **tokenizer** for our transformer of choice and put a `FastAI` wrapper on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.transform.Tokenizer"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roberta'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, be carefull about 3 things :\n",
    "\n",
    "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
    "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
    "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with add_prefix_space set to True.\n",
    "\n",
    "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the [HuggingFace documentation](https://huggingface.co/transformers/) in each model section.<br>\n",
    "`bert:       [CLS] + tokens + [SEP] + padding`<br>\n",
    "`roberta:    [CLS] + prefix_space + tokens + [SEP] + padding`<br>\n",
    "`distilbert: [CLS] + tokens + [SEP] + padding`<br>\n",
    "`xlm:        [CLS] + tokens + [SEP] + padding`<br>\n",
    "`xlnet:      padding + [CLS] + tokens + [SEP]`\n",
    "\n",
    "It is worth noting that we don't add padding in this part of the implementation.  As we will see later, fastai manage it automatically during the creation of the `DataBunch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalizer\n",
    "In `fastai` library, `NumericalizeProcessor` object takes as `bocab` argument a `Vocab` object. Here we will create a new class `TransformerVocab` that inherits from `Vocab` and overwrite `numericalize` and `textify` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize numericalize processor\n",
    "Notice taht we need to pass the `include_bs=False` and `include_eos=False` options. This is because `fastiai` adds its own special tokens by default which interferes with the `[CLS]` and `[SEP]` tokens that are required for RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.NumericalizeProcessor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumericalizeProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use RoBERTa tokenizer to initialize the `TransformersVocab\n",
    "transformer_vocab = TransformersVocab(tokenizer=transformer_tokenizer)\n",
    "\n",
    "# create a customized numericalizor using vocab just created\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put together our customized processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.TokenizeProcessor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenizeProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function over the tokenizer we created above\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally put the two processors in a list for later use\n",
    "transformer_processor = [OpenFileProcessor(),tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataBunch\n",
    "For the DataBunch creation, you have to pay attention to set the processor argument to our new custom processor `transformer_processor` and manage correctly the padding.\n",
    "\n",
    "As mentioned in the [HuggingFace documentation](https://huggingface.co/transformers/), BERT, RoBERTa, XLM and DistilBERT are models with absolute position embeddings, so it's usually advised to pad the inputs on the right rather than the left. Regarding XLNET, it is a model with relative position embeddings, therefore, you can either pad the inputs on the right or on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are using Google XLNet\n",
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'Ġcat', 'Ġdidnt', 'Ġjump', 'Ġonto', 'Ġthe', 'Ġtable', ',', 'Ġbecause', 'Ġits', 'Ġtired']\n",
      "[627, 4758, 46405, 3704, 2500, 5, 2103, 6, 142, 63, 7428]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'Ġcat',\n",
       " 'Ġdidnt',\n",
       " 'Ġjump',\n",
       " 'Ġonto',\n",
       " 'Ġthe',\n",
       " 'Ġtable',\n",
       " ',',\n",
       " 'Ġbecause',\n",
       " 'Ġits',\n",
       " 'Ġtired']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('the cat didnt jump onto the table, because its tired')\n",
    "print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the full IMDB dataset and inspect the files under that path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/projectx/.fastai/data/imdb')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/models'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/lm_databunch_RoBERTa'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/test'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/imdb_textlist_classifier'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/lm_databunch'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/pos'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/train/neg')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/projectx/.fastai/data/imdb/test/pos'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/test/labeledBow.feat'),\n",
       " PosixPath('/home/projectx/.fastai/data/imdb/test/neg')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'test').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataBunch for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TransformersVocab at 0x7fc496cd75c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can play around with the batch_size as long as the GPU can take it\n",
    "bs = 48\n",
    "data_clas = (TextList.from_folder(path, vocab=transformer_vocab, processor=transformer_processor)                         # specify the path\n",
    "           .filter_by_folder(include=['train','test'])# exclude other folders\n",
    "           .split_by_folder(valid='test')                 #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "           .label_from_folder(classes=['neg', 'pos'])                    #label them all with their folders\n",
    "           .databunch(bs=bs))                                 # convert to databunch for the learner later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : <s>\n",
      "[SEP] token : </s>\n",
      "[PAD] token : <pad>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠLess Ġthan Ġ10 Ġminutes Ġinto Ġthis Ġfilm ĠI Ġwanted Ġit Ġto Ġend Ġas Ġit Ġwas Ġpainful . ĠAll Ġthis Ġ\" hor ror \" Ġmovie Ġwas Ġabout Ġwas Ġa Ġgroup Ġof Ġwh iny Ġbit ches Ġdoing Ġstupid Ġthings Ġfor Ġ90 Ġminutes , Ġarguing , Ġcrying Ġand Ġscreaming . ĠDo Ġnot Ġlet Ġthe Ġpositive Ġreviews Ġfool Ġyou Ġas Ġthis Ġreally Ġis Ġa Ġterrible Ġmovie Ġand Ġyou Ġreally Ġshouldn 't Ġwatch Ġit</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠExcellent Ġdocumentary , Ġostensibly Ġabout Ġthe Ġfriendship Ġand Ġsubsequent Ġrivalry Ġbetween Ġtwo ĠWest ĠCoast Ġretro Ġrock ' n ' roll Ġbands : ĠThe ĠD andy ĠWar hol s Ġand Ġthe ĠBrian ĠJon est own ĠMassacre . ĠWhat Ġit Ġactually Ġturns Ġout Ġto Ġbe Ġis Ġa Ġportrait Ġof Ġa Ġborderline Ġpsychopath Ġ- ĠAnton ĠNew comb Ġ- Ġand Ġhis Ġtortured Ġrelationship Ġwith Ġthe Ġrest Ġof Ġthe Ġworld . ĠInterestingly , Ġfor</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠThe ĠBour ne ĠUlt im atum Ġ- ĠJason ĠBour ne Ġ( Matt ĠDamon Ġin Ġhis Ġbest Ġrole Ġever ), Ġthe Ġnewest Ġspy Ġkid Ġon Ġthe Ġblock , Ġbrings Ġhis Ġquest Ġfor Ġhis Ġidentity Ġto Ġa Ġclose Ġas Ġhe Ġalso Ġseeks Ġto Ġend Ġthe ĠCIA 's Ġlatest Ġprogram Ġ\" Black b ri ar \" Ġto Ġmake Ġsuper Ġassassins Ġlike Ġhimself .&lt; br Ġ/ &gt;&lt; br Ġ/&gt; I Ġwas Ġso Ġpsy</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠThe ĠBritish ĠPublic ĠSchool Ġsystem Ġdid Ġnot Ġevolve Ġsolely Ġwith Ġthe Ġidea Ġof Ġeducating Ġthe Ġupper Ġclasses Ġdespite Ġthat Ġpopular Ġand Ġwidespread Ġmisconception . It Ġwas Ġdesigned Ġto Ġproduce Ġadministrators Ġand Ġgovernors , civil Ġservants Ġand Ġmilitary Ġmen Ġto Ġrun Ġthe ĠBritish ĠColon ies . These Ġpeople Ġwere Ġalmost Ġentirely Ġrecruited Ġfrom Ġthe Ġmiddle Ġclasses . When Ġthe ĠPublic ĠSchools Ġhad Ġbegun Ġto Ġshow Ġtheir Ġworth Ġthe Ġsc ions</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠTHE ĠHOUSE ĠTHAT ĠDR IPP ED ĠBL OOD Ġis Ġthe Ġthird Ġin Ġa Ġseries Ġof Ġseven ĠAm icus Ġhorror Ġanth ologies . ĠIf ĠTHE ĠMON STER ĠCL UB Ġis Ġincluded Ġas Ġpart Ġof Ġthe Ġseries , Ġthis Ġwould Ġmake Ġeight Ġmovies . ĠAlthough , Ġthat Ġmovie Ġis Ġvery Ġdifferent Ġfrom Ġthe Ġothers .&lt; br Ġ/ &gt;&lt; br Ġ/&gt; I Ġlook Ġupon Ġthe ĠAm icus Ġanth ologies Ġwith Ġgreat Ġmemories</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 0\n",
      "[SEP] id : 2\n",
      "[PAD] id : 1\n",
      "Batch shape :  torch.Size([48, 512])\n",
      "tensor([[    0,    85,    18,  ...,     6,    24,     2],\n",
      "        [    0,   286,   162,  ...,  1065,    16,     2],\n",
      "        [    0,   572,    45,  ...,   219,     8,     2],\n",
      "        ...,\n",
      "        [    0,   152,    16,  ...,     4,   382,     2],\n",
      "        [    0,  3224,    89,  ...,     6,     8,     2],\n",
      "        [    0,  1308,  2335,  ..., 13585,   960,     2]])\n"
     ]
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = data_clas.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                attention_mask = attention_mask)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = 2\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the encoder's pre-trained weights from the language model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-8464c2ea8e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'learn_lm_encoder_IMDB'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcustom_transformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'{name}.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mroot_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 deserialized_objects[root_key] = restore_location(\n\u001b[0;32m--> 504\u001b[0;31m                     data_type(size), location)\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m     79\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# name = 'learn_lm_encoder_IMDB'\n",
    "# custom_transformer_model.transformer.roberta.load_state_dict(torch.load(path/'models'/f'{name}.pth', map_location=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(data_clas, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = CustomAdamW, \n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For roberta-base\n",
    "list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "              learner.model.transformer.roberta.encoder.layer[0],\n",
    "              learner.model.transformer.roberta.encoder.layer[1],\n",
    "              learner.model.transformer.roberta.encoder.layer[2],\n",
    "              learner.model.transformer.roberta.encoder.layer[3],\n",
    "              learner.model.transformer.roberta.encoder.layer[4],\n",
    "              learner.model.transformer.roberta.encoder.layer[5],\n",
    "              learner.model.transformer.roberta.encoder.layer[6],\n",
    "              learner.model.transformer.roberta.encoder.layer[7],\n",
    "              learner.model.transformer.roberta.encoder.layer[8],\n",
    "              learner.model.transformer.roberta.encoder.layer[9],\n",
    "              learner.model.transformer.roberta.encoder.layer[10],\n",
    "              learner.model.transformer.roberta.encoder.layer[11],\n",
    "              learner.model.transformer.roberta.pooler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 14 groups\n",
      "[Sequential(\n",
      "  (0): Embedding(50265, 768, padding_idx=1)\n",
      "  (1): Embedding(514, 768, padding_idx=1)\n",
      "  (2): Embedding(1, 768)\n",
      "  (3): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (4): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1)\n",
      "  (4): Linear(in_features=768, out_features=2, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "learner.split(list_layers)\n",
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learner.layer_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('untrained_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.load('untrained_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.freeze()\n",
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 2.51E-03\n",
      "Min loss divided by 10: 5.25E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end = 10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.497337</td>\n",
       "      <td>0.340582</td>\n",
       "      <td>0.857400</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>10:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.450775</td>\n",
       "      <td>0.293370</td>\n",
       "      <td>0.883440</td>\n",
       "      <td>0.116560</td>\n",
       "      <td>09:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.397529</td>\n",
       "      <td>0.272006</td>\n",
       "      <td>0.889160</td>\n",
       "      <td>0.110840</td>\n",
       "      <td>09:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.375950</td>\n",
       "      <td>0.257950</td>\n",
       "      <td>0.898600</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>09:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.358261</td>\n",
       "      <td>0.257403</td>\n",
       "      <td>0.899240</td>\n",
       "      <td>0.100760</td>\n",
       "      <td>10:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, 2.51e-03, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17' class='' max='520', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      3.27% [17/520 00:13<06:51 0.3112]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.freeze_to(-1)\n",
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_end = 10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for LM training\n",
    "The reviews are in a training and test folder. In addition, we have a 'unsup' folder that contains many reviews are \n",
    "are **not labelled**.<br>\n",
    "In the second training phase of ULMFiT, as mentioned in the [README](https://github.com/Sylar257/Sentiment-Analysis/blob/master/README.md)\n",
    ", we will be fine-tuning the language model to the domain-specific corpus.<br>\n",
    "Thus, training could take advantage of using 'train', 'test', and 'unsup' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataBunch for language model\n",
    "What does that mean?<br>\n",
    "Basically we are creating a databunch for our learner later in a way that we ignore the true label('negataive' or  'positive'). Hence, the task we constructed is as simple as to just predict the **next word** without worrying about what the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# we can play around with the batch_size as long as the GPU can take it\n",
    "bs = 48\n",
    "data_lm = (TextList.from_folder(path, processor=transformer_processor)                         # specify the path\n",
    "           .filter_by_folder(include=['train','test','unsup'])# exclude other folders\n",
    "           .split_by_rand_pct(0.1, seed=seed)                 # randomly split and keep 10% for validation set\n",
    "           .label_for_lm()                                    # label as to \"predict the next word token\"\n",
    "           .databunch(bs=bs))                                 # convert to databunch for the learner later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_lm.train_ds), len(data_lm.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a peek at a small sample of data\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save our databunch so that we don't have to re-run this the next time\n",
    "data_lm.save('lm_databunch_RoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the databunch we created ealier\n",
    "# bs = 48\n",
    "# data_lm = load_data(path, 'lm_databunch_RoBERTa', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sanity check for <s>; </s>; <pad>\n",
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = data_lm.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize model\n",
    "As mentioned [here](https://github.com/huggingface/transformers#models-always-output-tuples), every model's forward method always outputs a tuple with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits.  One way to access them is to create a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel_Encoder(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel_Encoder,self).__init__()\n",
    "        self.transformer = transformer_model.roberta\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                attention_mask = attention_mask)[0]   \n",
    "        return ([logits],[logits])\n",
    "    # this function is added because fastai `learner.lr_find()` will call it\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pretrained weights for RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is the configuration of language model\n",
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = transformer_tokenizer.vocab_size\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel_Encoder(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(model, split_on:SplitFuncOrIdxList)->None:\n",
    "    \"Split the model at `split_on`.\"\n",
    "    if isinstance(split_on,Callable): split_on = split_on(self.model)\n",
    "    layer_groups = split_model(model, split_on)\n",
    "    return layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For roberta-base\n",
    "list_layers = [custom_transformer_model.transformer.embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = split(custom_transformer_model,list_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoder[0][0]\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-construct decoder using FastAI LinearDecoder\n",
    "\n",
    "decoder = LinearDecoder(transformer_tokenizer.vocab_size, \n",
    "                        n_hid=768, \n",
    "                        output_p=0.1,\n",
    "                        tie_encoder=enc,\n",
    "                        bias=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequentialRNN(custom_transformer_model, decoder)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm = LanguageLearner(data_lm, \n",
    "                           model,\n",
    "#                            split_func=tfmer_lm_split,\n",
    "                           opt_func = CustomAdamW)\n",
    "learn_lm.callbacks.append(ShowGraph(learn_lm))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "# if use_fp16: learn_lm = learn_lm.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For roberta-language-model\n",
    "list_layers = [learn_lm.model[0],\n",
    "              learn_lm.model[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.split(list_layers)\n",
    "num_groups = len(learn_lm.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learn_lm.layer_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the model is split into two part Encoder and classifier which enables us to save just the encoder weights later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_lm.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# learn_lm.freeze()\n",
    "learn_lm.lr_find()\n",
    "learn_lm.recorder.plot(skip_end=10,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "learn_lm.fit_one_cycle(5, lr, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the encoder of the language model and save it's encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn_lm.model)[0].transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'learn_lm_encoder_IMDB'\n",
    "torch.save(encoder.state_dict(), learn_lm.path/learn_lm.model_dir/f'{name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path/'models').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old ULMFiT code for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the drop_mult decide the percentage of dropout to use in relation to the combination used in the original paper\n",
    "learn_lm_AWD = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "As we can see below, when we create `TextDataBunch` a  `vocab` property is created simultaneously. <br>\n",
    "It's worth pointing out that, for `index-to-strings` and `strings-to-index` we have a different length. This is primarily because that there are some words that appear infrequently so that it's not effcient for them to occupy one token. What we do is to map all of these low frequency words to `xxunk`. We can ditermine the `min_freq` in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = data_lm.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.stoi[\"stingray\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.stoi[\"happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.itos[vocab.stoi['mamamia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learn_lm.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ourmodel has two parts, the AWD_LSTM base architecture and the linear classifier\n",
    "learn_lm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on `drop_mult`\n",
    "From the original [AWD_LSTM paper](https://arxiv.org/pdf/1708.02182.pdf) the authors applied several effective techniques.<br>\n",
    "\n",
    "**DropConnect** was implemented in the architecture in that weight matrices are *dropped* before the *forward* and *backward* pass.<br>\n",
    "\n",
    "**Variational dropout**. In standard dropout, a new binary dropout mask is sampled each and every time the dropout function is called. **Variational dropout** only samples a *dropout mask* upon the first call and then will repeatedly use that *locked dropout* mask for all repeated connections within the forward and backward pass.<br>\n",
    "\n",
    "The values used for *dropout on the word vectors*, the *output between LSTM layers*, the *output of the final LSTM layer*, and *embedding dropout* were (0.4, 0.3, 0.4, 0.1), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Encoder is the first layer of the AWD_LSTM, which is also known as the `embedding layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = learn_lm.model[0].encoder\n",
    "enc.weight.size()  # 400 is the embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that 60000 is the vocab size of our language model vocabulary\n",
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before training\n",
    "Let's try to use this model(only pre-trained with wiki-text) to generate fake movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = 'The color of the sky is'\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the 'temperature' denote the randomness we adopt when pick next words\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'temperature'  set to super low, there will be almost no randomness\n",
    "N_SENTENCES = 3\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.05) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change TEXT\n",
    "TEXT = 'I hate this movie so much'\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc(LanguageLearner.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning a language model\n",
    "We can use the `data_lm` object we created earlier to fine-tune a pretrained language model. \n",
    "Here we will be using a pre-trained `AWD-LSTM` architecture theat is available in FastAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot function attached to lr_finder\n",
    "# Note that we get a smoothened version where `skip_start` and `skip_end` decide howmuch to trim-off from start or end\n",
    "\n",
    "def plot(self, skip_start:int=10, skip_end:int=5, suggestion:bool=False, return_fig:bool=None,\n",
    "             **kwargs)->Optional[plt.Figure]:\n",
    "        \"Plot learning rate and losses, trimmed between `skip_start` and `skip_end`. Optionally plot and return min gradient\"\n",
    "        lrs = self._split_list(self.lrs, skip_start, skip_end)\n",
    "        losses = self._split_list(self.losses, skip_start, skip_end)\n",
    "        losses = [x.item() for x in losses]\n",
    "        if 'k' in kwargs: losses = self.smoothen_by_spline(lrs, losses, **kwargs)\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.plot(lrs, losses)\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_xlabel(\"Learning Rate\")\n",
    "        ax.set_xscale('log')\n",
    "        ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
    "        if suggestion:\n",
    "            try: mg = (np.gradient(np.array(losses))).argmin()\n",
    "            except:\n",
    "                print(\"Failed to compute the gradients, there might not be enough points.\")\n",
    "                return\n",
    "            print(f\"Min numerical gradient: {lrs[mg]:.2E}\")\n",
    "            ax.plot(lrs[mg],losses[mg],markersize=10,marker='o',color='red')\n",
    "            self.min_grad_lr = lrs[mg]\n",
    "            ml = np.argmin(losses)\n",
    "            print(f\"Min loss divided by 10: {lrs[ml]/10:.2E}\")\n",
    "        if ifnone(return_fig, defaults.return_fig): return fig\n",
    "        if not IN_NOTEBOOK: plot_sixel(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim the last 15 datapoints so that we have clearer view\n",
    "learn_lm.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to select a `learning_rate` where the slope is steep and not going upwards.<br>\n",
    "`lr=5e-3` seems to be a sensible choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=5e-3\n",
    "learn_lm.to_fp16()\n",
    "learn_lm.fit_one_cycle(5, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save('fit_freezed_5_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.load('fit_freezed_5_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we see that the aacuracy is positively improving\n",
    "# we can unfreeze and train further\n",
    "learn_lm.unfreeze()\n",
    "learn_lm.fit_one_cycle(10,lr/5, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save('fine_tuned_lm')\n",
    "learn_lm.save_encoder('fine_tuned_lm_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"i liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"This movie was\"\n",
    "N_WORDS = 30\n",
    "N_SENTENCES = 2\n",
    "print(\"\\n\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the language model is much more \"*IMDB like*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 48\n",
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs, num_workers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.save('imdb_textlist_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ultimate-model: IMDB review classifier\n",
    "Three simple steps to create our review classifier after fine tuning our language model with IMDb dataset:\n",
    "    1. Create a `text_classifier_learner` with `AWD_LSTM` as base archietecture(note that we can use any model here as base architecture, but it has to be the same with the one we just trained as language model. So if we want a transformer here, we would be training a transformer language model in the previous section)\n",
    "    2. Load the `fine-tuned-language-model-encoder`. We have save both the encoder as well as the entire model. We would only be needing the encoder's weights here as we will be replacing the head as a freshly initialize classifier and train it later.\n",
    "    3. Freeze the body(base architecture) of our model, and train just the head first. We can make use of our usual trategy be looking for the optimal learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.3)\n",
    "learn_clas.load_encoder('fine_tuned_lm_enc')\n",
    "learn_clas.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will be turning our model to mixed-precision in order to speed up the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.to_fp16();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.fit_one_cycle(10, 2e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_freezed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradual unfreezing during fine-tuning our classifier\n",
    "Fine-tuning the target classifier is the most critical part of the *transfer learning method*. Overly aggressive fine-tuning will cause catastrophic forgetting, eliminating the benefit of the information captured through language modeling; too cautious fine-tuning will lead to slow convergence (and resultant overfiting). Besides discriminative fine-tuning and triangular learning rates, **gradual unfreezing** is proposed.\n",
    "\n",
    "Jeremy et al. found that for RNN-base NLP models, by gradually unfreeze the layers from head to bottom we minimize the forgetting incurred for each *transfer learning* thus maximize our effort done in the previous training section.\n",
    "\n",
    "We first unfreeze the **last layer** and fine-tune all un-frozen layers for one epoch.\n",
    "\n",
    "Then unfreeze the **next lower frozen layer** and repeat.\n",
    "\n",
    "Until all unfrozen layers converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(5, slice(1e-2/(2.6**4),1e-2), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreed_second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.freeze_to(-3)\n",
    "learn_clas.fit_one_cycle(5, slice(5e-3/(2.6**4), 5e-3), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreezed_third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.load('learn_clas_unfreezed_third');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.unfreeze()\n",
    "learn_clas.fit_one_cycle(15, slice(4e-4/(2.6**4),5e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.save('learn_clas_unfreezed_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state-of-the-art result for IMDB sentimant classification result in 2017 is **94.1%**\n",
    "What we can do even better, is to build a **reversed model** as well and training a meta-learner on top of that.\n",
    "For this technique, we will be experimenting with more detail in my [sentiment analysis with non-English language]() repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
